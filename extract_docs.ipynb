{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dvdblk/hack4good-oecd/blob/main/extract_docs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vg3eJelQT7T3"
      },
      "outputs": [],
      "source": [
        "!pip install langchain faiss-cpu openai tiktoken"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Z3iqXDK6T6bX"
      },
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.base import AttributeInfo\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "from langchain.embeddings import OpenAIEmbeddings\n",
        "from langchain.vectorstores import Chroma, FAISS\n",
        "from langchain.prompts import ChatPromptTemplate\n",
        "from langchain.schema.output_parser import StrOutputParser\n",
        "from langchain.schema.runnable import RunnablePassthrough, RunnableLambda\n",
        "\n",
        "import re\n",
        "import os\n",
        "import openai\n",
        "import tiktoken\n",
        "from operator import itemgetter\n",
        "import typing\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import copy\n",
        "import time\n",
        "import json\n",
        "\n",
        "from topic import Topic, recursive_topic_creator\n",
        "from util import get_standard_doc_splits\n",
        "from query_handler import QueryHandler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "FnFBM6goT6be"
      },
      "outputs": [],
      "source": [
        "OPENAI_API_KEY = \"redacted\"\n",
        "openai.api_key = OPENAI_API_KEY\n",
        "os.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yr-lbHbrT6bg"
      },
      "outputs": [],
      "source": [
        "multiple_q_dict = {\n",
        "    \"questions\" : [\"summary\", \"binary\"],\n",
        "    \"top\" : {\n",
        "        \"summary\": \"Summarize whether and how {topic} is mentioned in the document.\",\n",
        "        \"binary\": \"Is {topic} mentioned in the document?\",\n",
        "        \"sentiment\": \"How is the sentiment towards {topic} in the document?\"},\n",
        "    \"relation\" :{\n",
        "        \"summary\": \"With regard to {topic}, summarize whether and how the document mentions {subtopic}.\",\n",
        "        \"binary\": \"With regard to {topic}, does the document mention {subtopic}?\",\n",
        "        \"sentiment\": \"With regard to {topic}, what is the sentiment of {subtopic} in the document?\"},\n",
        "    \"link\": {\"basic\": \"With regard to {technology} does the document mention {skill_caps}?\"},\n",
        "    # policy, investment\n",
        "    \"formatting\" : {\n",
        "        \"summary\": \" Use 20 words or less.\",\n",
        "        \"binary\": \" Yes -> 1 or No -> 0\", # \" Answer 1 for yes, 0 for no\"\n",
        "        \"sentiment\": \" Positive -> 1, Negative -> -1, or Neutral -> 0\"} # \" Answer 1 for positive, 0 for neutral and -1 for negative sentiment\"\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fd0mAwdQWCSk"
      },
      "outputs": [],
      "source": [
        "# RUN TO RESET PROGRESS\n",
        "import importlib\n",
        "import query_handler\n",
        "importlib.reload(query_handler)\n",
        "all_files_results = {}\n",
        "\n",
        "CHUNK_SIZE = 2000\n",
        "\n",
        "df = pd.read_csv('topic_datasheet.csv')\n",
        "topics = recursive_topic_creator(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_D1VBFfVZ0qP"
      },
      "outputs": [],
      "source": [
        "file_lst = os.listdir(\"data\")\n",
        "folder = \"data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rRJIJWQT6bm"
      },
      "outputs": [],
      "source": [
        "working_lst = [i for i in file_lst if i not in all_files_results.keys()]\n",
        "\n",
        "for f in working_lst:\n",
        "    print(\"working on: \", f)\n",
        "    splits = get_standard_doc_splits(folder+f, chunk_size=CHUNK_SIZE)\n",
        "    vectorstore = FAISS.from_documents(splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "    qh = query_handler.QueryHandler(\n",
        "        topics,\n",
        "        multiple_q_dict,\n",
        "        vectorstore,\n",
        "        rag_topk=8,\n",
        "        model_name=\"gpt-4-1106-preview\", #\"gpt-3.5-turbo-1106\",\n",
        "        query_json_split_size=3,\n",
        "        sleep_time=1)\n",
        "\n",
        "    res = qh.run()\n",
        "    res[\"chunk_size\"] = CHUNK_SIZE\n",
        "    res[\"additional_notes\"] = \"\"\n",
        "\n",
        "    all_files_results[f] = res"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Ask Advanced Questions"
      ],
      "metadata": {
        "id": "d_9w0Y1NK1wJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "specific_question = {\n",
        "    \"policy\": {\n",
        "        \"summary\": \"Summarize policies, if any, the document recommends for {topic} in one sentence.\",\n",
        "        \"binary\": \"Does the document recommend any policies for {topic}? Answer 1 for yes, 0 for no.\"\n",
        "    },\n",
        "    \"investment\": {\n",
        "        \"summary\": \"Summarize the investment, if any, the document recommends for {topic} in one sentence.\",\n",
        "        \"binary\" : \"Does the document recommend investment for {topic}? Answer 1 for yes, 0 for no.\"\n",
        "    }\n",
        "}\n",
        "# \"sentiment\": \"For {topic} is the sentiment positive, negative or neutral? Output 1 for positive, -1 for negative, 0 for neutral.\""
      ],
      "metadata": {
        "id": "kLi36OBhOeHX"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "importlib.reload(query_handler)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sxPMeYyIPzTv",
        "outputId": "e410e6f6-e98a-4a74-f290-2a091651dbae"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<module 'query_handler' from '/content/query_handler.py'>"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extended_results = {}\n",
        "for key in all_files_results.keys():\n",
        "    print(\"working on: \", key)\n",
        "    splits = get_standard_doc_splits(folder+key, chunk_size=CHUNK_SIZE)\n",
        "    vectorstore = FAISS.from_documents(splits, embedding=OpenAIEmbeddings())\n",
        "\n",
        "    qh = query_handler.QueryHandler(\n",
        "        topics,\n",
        "        multiple_q_dict,\n",
        "        vectorstore,\n",
        "        rag_topk=8,\n",
        "        model_name=\"gpt-3.5-turbo-1106\", #\"gpt-4-1106-preview\",\n",
        "        query_json_split_size=3,\n",
        "        sleep_time=1)\n",
        "\n",
        "    extended_results[key] = qh.traverse_advanced(all_files_results[key][\"content\"], specific_question)"
      ],
      "metadata": {
        "id": "8johWxwGN48a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count_binaries = 0\n",
        "xfile = \"UK_36.txt\"\n",
        "for key in extended_results[xfile].keys():\n",
        "    for k in extended_results[xfile][key].keys():\n",
        "        if \"binary\" in k:\n",
        "            count_binaries += extended_results[xfile][key][k]\n",
        "print(count_binaries)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFowa72T7KMf",
        "outputId": "fd2eebf4-5f15-47e5-f4fa-31ee7ee2aa11"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "54\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "extended_results[xfile][\"Advanced Computing\"]"
      ],
      "metadata": {
        "id": "a5HeljijH1kF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2oN7KhyidCN"
      },
      "outputs": [],
      "source": [
        "# oh a new function\n",
        "def json_to_dataframe(doc_dict):\n",
        "    df = pd.DataFrame()\n",
        "    for file_key in doc_dict.keys():\n",
        "        file_dict = doc_dict[file_key]\n",
        "        to_pd_dict = {}\n",
        "        for topic in file_dict.keys():\n",
        "            if topic == \"questions\":\n",
        "                continue\n",
        "            if isinstance(file_dict[topic], dict):\n",
        "                my_dict = {}\n",
        "                for k in file_dict[topic].keys():\n",
        "                    my_dict[\n",
        "                        topic.title().replace(\" \", \"\") + \"_\" + k.title().replace(\" \", \"\")\n",
        "                        ] = file_dict[topic][k]\n",
        "                # my_dict = file_dict[topic].copy()\n",
        "\n",
        "                # my_dict[topic] = my_dict['general']\n",
        "                # my_dict.pop('general', None)\n",
        "\n",
        "                to_pd_dict.update(my_dict)\n",
        "            # else:\n",
        "            #     print(topic, file_dict[topic])\n",
        "\n",
        "        for key in to_pd_dict.keys():\n",
        "            to_pd_dict[key] = int(to_pd_dict[key])\n",
        "\n",
        "        to_pd_dict[\"doc_name\"] = file_key\n",
        "        df = pd.concat([df, pd.DataFrame([to_pd_dict])], ignore_index=True)\n",
        "\n",
        "\n",
        "    cols = list(df.columns.values)\n",
        "    cols = [cols[-1]] + cols[:-1]\n",
        "    df = df[cols]\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = json_to_dataframe(all_files_results)"
      ],
      "metadata": {
        "id": "JeKc5XKM4rr-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df)"
      ],
      "metadata": {
        "id": "JUlqtCxZqFuV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_csv(\"first_binary_datasheet.csv\")"
      ],
      "metadata": {
        "id": "nrAKXt6X5pm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(all_files_results, open(\"all_files_results.json\", \"w\"))"
      ],
      "metadata": {
        "id": "G5aW0ZKqoOQp"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "h4g",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}