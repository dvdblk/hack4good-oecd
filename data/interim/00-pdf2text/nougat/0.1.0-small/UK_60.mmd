[MISSING_PAGE_EMPTY:6055]

###### Contents

* 1 Executive summary
	* 1.1 Overview
	* 1.2 Key findings
	* 1.3 Key recommendations
* 2 Introduction
	* 2.1 Project background, scope and research questions
	* 2.2 Reflexivity and review limitations
* 3 Methodology
	* 3.1 Overview
	* 3.2 Data collection
	* 3.3 Data reduction
	* 3.4 Evaluation framework
	* 3.5 Descriptive analysis of the UK dataset
* 4 Previous work
	* 4.1 Overview
	* 4.2 Gender
	* 4.3 Disability
	* 4.4 Race and ethnicity
	* 4.5 Sexual orientation and gender reassignment
	* 4.6 Chapter summary
* 5 What works?
	* 5.1 Overview
	* 5.2 Training or development
	* 5.3 Strategies, policies or processes
	* 5.4 Career development programmes
	* 5.5 Recognition schemes
	* 5.6 Employer engagement and outreach
	* 5.7 Why were these interventions more or less effective?
	* 5.8 Chapter summary
* 6 Measuring success
	* 6.1 Overview
	* 6.2 Methodological hierarchies
	* 6.3 Outcome measurement and reporting
	* 6.4 Chapter summary
* 7 Enhancing data and disclosure
	* 7.1 Overview
	* 7.2 Categorisation
	* 7.3 Drivers
	* 7.4 Encouraging disclosure
	* 7.5 Limitations and future work

[MISSING_PAGE_FAIL:4]

## Chapter 4

### Overview

UK Research and Innovation (UKRI) commissioned Advance HE to review equality, diversity and inclusion (EDI) challenges and interventions in the research and innovation (R&I) sector. This review examines the UK **context only** (a concurrent review examines the international context).

A review of literature, both academic and 'grey', and responses to a Call for Evidence were used to address the following five research questions:

* which organisations have previously reviewed and explored the key challenges for EDI in the R&I landscape?
* among interventions implemented by organisations comparable to UKRI, which have proven effective, or less effective, and why?
* how is the effectiveness of EDI interventions measured and are there methods that are particularly useful for the R&I landscape?
* how can EDI data capture and disclosure rates in the R&I landscape be improved?
* which organisations are leading in terms of EDI in R&I?

### Key findings

#### Focus on gender and general EDI

A large proportion of sources focused on gender (or sex) equality, with most aimed at women, or EDI in general (for example, information related to identity characteristics is removed before job applications are reviewed). A smaller proportion of sources discussed other characteristics, such as age, disability or socio-economic status, as the primary target of interventions.

#### Focus on research careers and HE

The vast majority of interventions identified in this review related to higher education (HE) and research careers (for example, the recruitment of diverse academic staff or fellows). Although a sizable number of sources also discussed STEM employers, this review identified a gap in relation to EDI interventions in other areas of the R&I landscape (in particular, work related to innovation).

#### A diversity of EDI interventions

The review located a wide range of work taking place, such as:

* training (for example, on race equality and unconscious bias)
* strategies, policies or processes (for example, on national funding, recruitment, family-friendly and career breaks)
* career development programmes (for example, mentoring and leadership training)
* recognition schemes (for example, charters and awards)
* employer engagement and outreach (for example, industry collaboration and widening access).

#### National differences among interventions

Half of the interventions had a UK-wide focus. Around one quarter focused on England and one quarter on Scotland. One intervention from Northern Ireland and one intervention from Wales were identified in one review source, although they were not evaluated as they did not meet the review's inclusion criteria (such as the need to include some measurement of outcomes).

#### Effectiveness of interventions

We found a variety of evaluation methods and approaches to the reporting of outcomes. The diversity of methods and approaches made it difficult to assess effectiveness (for example, in terms of impact and sustainability). However, common themes included the following:

* sources reported a greater ability to demonstrate the efficacy of training, national-level funding interventions, recognition schemes, leadership development programmes and employer engagement and outreach projects; evidence was also identified to show that some approaches from the private sector might work in the R&I context, such as returnships and executive sponsorship
* in contrast, among sources reviewed, there was no evidence to support the effectiveness of mentoring, family-friendly and career break policies; in place of a sustained assessment of impact, these examples instead presented data on uptake (for example, 80 people attended the training) and anecdotal feedback* interventions understood as successful, in terms of self-reported information and the measurement of data, tended to involve collaboration across and within organisations, have commitment from senior management and align with organisational or sectoral strategies
* common features of less effective interventions were a lack of staff resources, absence of ongoing support for an intervention, tight timescales and methodological issues related to small sample sizes and missing EDI data (such as failure to collect data on participants' identity characteristics).

### Evaluation methods

Very few sources reported an effect size or provided information on outcomes that went beyond measures of engagement or uptake. However, a small number of interventions used a mixed-method approach (for example, qualitative feedback paired with quantitative measures) to yield richer and more convincing evidence of their impact. More broadly, the review found that longer-term evaluation is needed across interventions, although this brings practical challenges related to the resourcing of EDI work.

#### EDI data

Practices related to the collection and use of EDI data varied across different parts of the R&I landscape. These differences impacted the ability to present a UK-wide picture of EDI across R&I and created challenges for the evaluation of interventions (such as lack of benchmarking data). Harmonisation of methods to collect and'measure' EDI are recommended, while acknowledging the particularities of organisational contexts and subject areas.

### Key recommendations for policy makers, funders, employers and research

* Implement interventions identified in the review, as appropriate to organisational contexts.
* Develop interventions that address EDI challenges beyond those related to gender.
* Develop interventions for areas of the R&I landscape that have historically received less attention, such as non-STEM industry collaboration.
* Expand the use of sophisticated and longer-term evaluation of EDI interventions to determine interventions' effectiveness across different contexts.
* Harmonise data collection methods across different parts of the R&I landscape, as far as is practicable, and develop overarching EDI benchmarking data.
* Consider ways to encourage, recognise and reward organisations leading on EDI in R&I.

Detailed recommendations for policy makers, research funders, employers and researchers are included in chapter 10.

## Chapter 2 Introduction

### Project background, scope and research questions

UKRI commissioned Advance HE to undertake a review of interventions used to address current EDI challenges in the R&I sector.

This exploratory study, conducted over 15 weeks, helps establish a picture of what is known about interventions and the antecedent challenges they were designed to address, in relation to the nine protected characteristics in the Equality Act 2010 and socio-economic status.

The review asked the following questions:

* which organisations have previously reviewed and explored the key challenges for EDI in the R&I landscape?
* among interventions implemented by organisations comparable to UKRI, which have proven effective, or less effective, and why?
* how is the effectiveness of EDI interventions measured? Are there methods particularly useful for the R&I landscape?
* how can EDI data capture and disclosure rates in the R&I landscape be improved?
* which organisations are leading in terms of EDI in R&I?

Although this review presents an overview of key challenges in the sector, it does not compare relative EDI data across different areas of UKRI's work (for example, differences in funding allocated to principal investigators, in terms of their gender, across research councils). UKRI intends to undertake further work on EDI data across UKRI in the near future.

Informed by engagement with stakeholders at a Challenge Workshop, as well as working with our Advisory Group, we focused on developing an understanding of EDI work that seeks to:

* **address instances of underrepresentation, differential needs and systemic disadvantage:** in R&I this could present as unequal representation compared with local or 'pipeline' populations in senior leadership positions, in terms of research grants, citations etc.
* support inclusion and reduce the impact of bias and discrimination on individuals and groups: this might include addressing different experiences of discrimination, bias and harassment within employment, postgraduate study etc.

The focus of the review was broad and considered work that had taken place within universities and research institutes, learned societies, government agencies, charities and the voluntary sector, and private companies. Data collected included academic papers, grey literature, responses to a targeted Call for Evidence and interventions from successful Silver and Gold Athena Scientific Women's Academic Network (SWAN) applications applications.

Research focused on work that has taken place since 1 January 2011 in organisations that share UKRI's role as a research funder, a leader in R&I policy, outreach and public engagement, and an employer of around 7,000 people. This review also located potentially transferable practices implemented outside of R&I organisations, such as within police forces or large accountancy firms.

This review collated evidence gathered and applied an evaluation framework to synthesise findings from across the different types of data source. Results from this synthesis present an evidence base for 'what worked?' and 'what did not work?' in response to a range of EDI challenges.

UKRI also commissioned a separate, concurrent review that examined these questions from an international perspective, also conducted by Advance HE. The Global Institute for Women's Leadership at King's College London undertook a third review focused specifically on bullying and harassment. As it is not always possible or appropriate to separate bullying and harassment from wider EDI issues, we recommend that the reports are read in conjunction with each other. UKRI's website presents further information on the background to all three reviews.

To provide external advice on the scope and methodology of the two reviews it produced, Advance HE recruited an Advisory Group of 11 members. The Advisory Group included members with backgrounds in R&I and/or EDIwho worked across the HE, voluntary and public sectors. For a full list of of group members, see the acknowledgments.

Findings from this review will shape the development of UKRI's EDI strategy and be shared widely with others in the sector to expand the evidence base on EDI interventions and facilitate the sharing of good practice.

### Reflexivity and review limitations

The practice of EDI research is not value-neutral and, as with other organisations, Advance HE's work in this area will invite a degree of subjectivity and bias. However, as both the'reviewer' of past interventions and the 'author or funder' of several sources discussed in the review, it is vital to consider the potential impact of Advance HE's position within the R&I sector on this review's findings.

Advance HE was formed in 2018 from the merger of the Equality Challenge Unit (ECU)', the Leadership Foundation for Higher Education and the Higher Education Academy. Advance HE and its legacy agencies had internal policy and research teams that authored reports on EDI interventions, many of which are discussed in this review. Advance HE and its legacy agencies also awarded funding to external teams (such as universities or private research companies) to undertake research. When funding was awarded to external teams, research was conducted independently from Advance HE and its legacy agencies. For these reasons, where sources were published by Advance HE but research was conducted externally, the author(s) or organisation that conducted the research are noted.

As with EDI research in general, the frames of reference brought to this review were also likely affected by researchers' identity characteristics and organisational and academic backgrounds. Taking account of these potential limitations, we recognised that:

* the review cannot present an objective or unbiased account of EDI interventions in R&I
* measures were required to address, as far as possible, the research team's inherent subjectivities and biases.

This review therefore followed a rigorous methodology that was intentionally designed to counter subjectivities and biases. As a way to further diversify the design of the methodology and ensure that input went beyond Advance HE staff and associates, an Advisory Group was recruited and two meetings were held to discuss the review's search terms, inclusion and exclusion criteria, targeted grey literature search and evaluation framework design.

However, even with these measures in place, the methodology followed meant that this review would not identify and analyse all possible sources related to EDI interventions in the UK, nor was this the intention of this research. Rather, the 15-week study identified a range of EDI interventions, via four data collection streams, and then used an evaluation framework to assess their effectiveness, evaluation methods used and approaches to data collection.

This review's methodology meant that effective EDI interventions will have taken place, since 1 January 2011 and within the context of the UK, that are not mentioned in this publication. This does not imply that these interventions failed to meet this review's inclusion criteria or adequately demonstrate effective results. Instead, all we can say is that the intervention was not identified via the methodology followed in this review.

Furthermore, this review identified a range of interventions implemented by organisations working within and outside R&I sectors to address challenges related to EDI. In many instances, sources that discussed these interventions included gaps (numerical data on outputs, clarity on evaluation method used etc.). In terms of sources reviewed that omitted key pieces of information, it was beyond this review's scope to plug the gaps or undertake further research to supplement information contained within there.

This acknowledgment of'missing' sources, and'missing' data within sources, is a reminder of this review's limitations. It also highlights that information presented here is not a universally prescriptive account of 'what works?', as this will depend on contextual factors and local resources. Failure to identify an intervention within this review should not, in itself, dissuade an organisation from investigating the utility of that intervention to address challenges identified.

## Chapter 8 Methodology

### Overview

Our methodology consisted of data collection via four streams and the development of an evaluation framework to qualify existing literature.

### Data collection

There were four main sources of data collection included in the current review.

* an extensive search of existing academic and grey literature using online search databases
* a targeted search for grey literature that included mining the websites of organisations known to have focused on EDI issues
* a Call for Evidence that involved primary data collection from R&I organisations
* a review of successful Athena SWAN applications from the two most recent rounds (November 2017 and April 2018) to identify additional evaluations of EDI interventions.

#### 3.2.1 Academic and grey literature database search

The search for existing literature was conducted via three main databases (EBSCO, Scopus and OpenGrey) and used Boolean search terms related to (i) EDI, (ii) interventions and (iii) R&I (see appendix 11.1.1). Due to the short timeframe for data collection, it was most practical for the UK and international research teams to use the same search terms and then sort eligible sources across the two reviews. Table 3.1 summarises the total number of sources identified through each database search.

#### 3.2.2 Targeted grey literature search

Alongside the database searches, a targeted search of UK organisational websites was undertaken to locate publications related to EDI interventions and reviews of key EDI challenges in the sector (see appendix 11.4 for the list of websites). Advance HE devised the list of websites and received further suggestions from Advisory Group members, UKRI's EDI External Advisory Group (EAG) and its Strategic Implementation Group (SIG). While the search could not be exhaustive, input from a diverse range of stakeholders ensured that it encompassed a broad sample of organisations from across the R&I landscape. The following types of organisation were included in the search:

* charities and non-governmental organisations (NGOs)
* equality and diversity organisations
* government and related bodies
* HE sector agencies
* learned societies
* private sector companies
* research councils and other funding bodies
* research institutes.

Searches on these websites involved using any function available to run a simple search using the terms 'equality,'diversity and 'inclusion'. Where a search function was not available, publications lists were scanned for relevant material. Higher education institutions (HEIs) were not included in the search as they were overrepresented in Call for Evidence responses and Athena SWAN submissions.

#### 3.2.3 Call for Evidence

The Call for Evidence was circulated between 28 January and 19 February 2019 using Advance HE and Advisory Group contacts, relevant Jisc mailing lists (**admin-eo**@jiscmail.ac.uk** and **riag**@jiscmail.ac.uk**) and UKRI's EAG and SIG. A form was developed to capture key information from institutions about interventions they had undertaken (see appendix 11.2.2). Questions were designed to be flexible so that respondents could share different types of intervention, and to prompt institutions to return information that would help answer the project's research questions.

\begin{table}
\begin{tabular}{l c} \hline \hline \multicolumn{1}{c}{**Data**} & \multicolumn{1}{c}{**Total number of UK and international sources identified**} \\ \hline EBSCO & 3,011 \\ OpenGrey & 684 \\ Scopus & 2,295 \\ Total & 5,990 \\ \hline \hline \end{tabular}
\end{table}
Table 3.1:

#### 3.2.4 Athena SWAN review

This strand of data collection involved the review of successful departmental and institutional UK Athena SWAN Silver and Gold applications from the November 2017 and April 2018 awards rounds. We limited this strand of data collection to the two most recent application rounds for two reasons: (i) this helped avoid unnecessary repetition in terms of the interventions described and (ii) his kept the number of Athena SWAN applications reviewed within a manageable amount given the timeframe of the current review.

Athena SWAN applications were imported into the qualitative analysis software Atlas. it and an in-document search was conducted to identify all instances of the search terms in the applications. Interventions that satisfied the review's inclusion criteria were marked with a 'code' that briefly described the intervention (for example, 'one-to-one support: research funding/management'). Sources were coded inductively (in other words read without _a priori_ expectations) to detect recurring themes.

### Data reduction

#### 3.3.1 Inclusion criteria

To limit the scope of the review and most effectively answer the review's research questions, inclusion and exclusion criteria were applied to all sources across all strands of data collection (see appendix 11.3.1 for a list of inclusion criteria and details regarding their application). Sources meeting the following criteria were selected for further analysis:

* published on or after 1 January 2011 (that is, after the Equality Act 2010 had come into place)
* discussed at least one protected characteristic from the 2010 Equality Act or Northern Ireland equality legislation
* published by a reputable source (an academic journal, book, organisation website etc.)
* evaluated an EDI intervention in an empirical manner, or a review or meta-analysis of EDI interventions
* relevant to R&I or to the funding, practice or communication of R&I
* available in English
* discussed interventions conducted in the UK.

The research team acknowledges that some of the excluded publications (blogs, book reviews, legal cases etc.) may include academic or empirical content. However, the high degree of variability in the quality and quantity of information present in these sources placed them beyond the timeframe and rigour of the current review. It is worth noting that review articles that did not present empirical information on interventions (such as those describing current EDI challenges or barriers) were excluded from analysis using the evaluation framework (described in section 3.4) but included in our discussion of which organisations have undertaken reviews of EDI challenges in chapter 4.

A team of four researchers (two for the UK review, two for the international review) manually reviewed the 5,990 sources identified. In total, 5,935 sources were excluded from the final UK dataset. Of these, 1,515 were duplicate sources (sources identified through more than one of the data collection methods). An additional 886 sources were inaccessible (that is behind a paywall or in a database that the research team could not access) and thus excluded from further analysis. Finally, 2,126 sources were excluded for not being an empirical evaluation or review or meta-analysis and 1,273 were excluded for not discussing at least one protected characteristic identified within the Equality Act 2010, or EDI in general. Finally, during the application of the evaluation framework, an additional 24 sources were removed from the list of eligible sources because they did not include an evaluation of an EDI intervention or were not accessible (in other words the articles were published in journals that were not available to the researchers through their current EBSCO subscription, were not published online or were archived and no longer available online). Of the remaining sources, 111 applied to the international context and, as such, were removed removed from this analysis.

Following testing, it became apparent that interventions from Athena SWAN applications could not be evaluated using the evaluation framework and they were therefore excluded from this element of the review. This resulted in a final sample of 55 sources representing 82 discrete interventions or reviews of multiple interventions.

#### 3.3.2 Reliability of inclusion criteria

To ensure that the eligibility criteria had been applied in a similar manner, a subsample of 10% of all identified sources was double-coded by a fifth researcher who was blind to which sources the research team had labelled as eligible. Overall, each criterion was applied in a similar manner with both the research team and the fifth researcher disqualifying: roughly 11% of subsample sources as duplicates (as the same source could be identified through the different streams of data collection): 9-10% as being inaccessible; and 63-64% as not referring to a protected characteristic, socio-economic status or EDI in general, or being an empirical evaluation, review, meta-analysis or gap analysis of EDI interventions, or evidence-based recommendations (see appendix 11.3.3 for a summary). It should be noted that the last two criteria were combined as many of the sources met both of these.

### Evaluation framework

#### 3.4.1 Design and application

The research team developed and applied an evaluation framework to extract the information in each source that was pertinent to the five research questions addressed in the current review. The evaluation framework (see appendix 11.5.2) involved applying labels or descriptors to each source's content, such as which protected characteristic was examined, what type of intervention was evaluated and which area of UKRI's work this intervention applied to. By converting the sources into a common rubric, this quantification facilitated the application of a number of synthesis techniques including tabulation (that is, how many sources employed a given evaluation method or discussed a specific protected characteristic), as well as grouping and clustering studies according to their applicability to each of the current research questions (such as sorting the database by evaluation method to identify most frequently applied methods - see chapter 6). The evaluation framework also provided us with the space to highlight important information or discussions within each source and to tease out content for additional qualitative analysis. The qualitative approaches applied within the current review included not only the identification of themes (such as what types of intervention are presented in the current database) but also the triangulation of methodologies and concepts across both the qualitative and the quantitative information present in the evaluation framework to determine how the interventions work, why they work and for whom.

As many of the sources described more than one intervention, the evaluation framework was applied to the individual interventions rather than the source. In other words, while the final UK sample included 55 sources, the total number of interventions evaluated was 82.

#### 3.4.2 Reliability

A similar process to that described for the reliability analysis of the inclusion criteria was undertaken with the application of the evaluation framework. Specifically, a subsample of 10% of all eligible sources (including some from the academic and grey literature, and Call for Evidence) was double-coded by a fifth researcher. Percent agreement between the research team and the fifth researcher was used to establish reliability, with a cut-off point for satisfaction being at least 80% agreement. Overall, percent agreement was acceptable for all categories except type of data and the Maryland Scientific Method Scale (see appendix 11.5.3 for the percent agreement for each variable). This was likely due to a large degree of variability in how methods and results were described in many of the sources. For example, in 37 out of 82 sources (or 45.1%), the applied methodology was either 'unclear'

\begin{table}
\begin{tabular}{l c c} \hline \hline \multicolumn{1}{c}{Strand} & No of & No of \\ \hline \multicolumn{1}{c}{Strand} & No of & Interantations \\ \hline \multicolumn{1}{c}{Academic and grey literature database search} & 12 & 12 \\ \hline \multicolumn{1}{c}{Targeted grey literature search} & 36* & 51 \\ \multicolumn{1}{c}{Call for Evidence} & 7 & 19 \\ \hline \multicolumn{1}{c}{Athena SWAN applications} & 23 & 18 \\ \hline \multicolumn{1}{c}{* An additional 14 grey literature sources were included in the review of challenges.} & \\ \end{tabular}
\end{table}
Table 2:or 'unknown'. Moreover, 38 (46.3%) of sources did not measure or report an outcome, making it difficult to ascertain what kind of data was collected and how it was analysed. Given the low percent agreement on these two categories, this data was reviewed and recoded by the research team as a unit prior to further analysis.

### Descriptive analysis of the UK dataset

The following analyses are based on the interventions presented in the academic, grey and Call for Evidence sources, as the evaluation framework was not applied to the Athena SWAN applications. An initial series of descriptive analysis of the quantitative components in the evaluation framework was undertaken to inform the content of our results sections, which are presented in chapters 5 through 8. Many of the categorical variables in the evaluation framework were not mutually exclusive; we therefore relabelled the raw data to represent both the original categories as well as how these categories were examined in combination (such as an intervention relevant both to UKRI's work on public engagement and to its R&I policy).

#### 3.5.1 Geographic coverage

Within the UK sample, there was a lack of representation of interventions from Northern Ireland and Wales (one source included an intervention from Northern Ireland and an intervention from Wales but did not provide information on outcomes). Of the 82 interventions analysed, 46 (56.8%) were UKwide, 18 (22.0%) related to England only and 18 (22.0%) to Scotland only.

#### 3.5.2 Coverage of identity characteristics

Roughly one third of the interventions analysed were related to promoting gender equality (31.7%, 26 interventions), with other identity characteristics receiving considerably less attention in the eligible academic literature:

* nine interventions (11.0%) evaluated an intervention related to pregnancy and maternity leave
* seven interventions (8.5%) looked at ethnicity, race or nationality
* four interventions (4.9%) considered disability (including mental health)
* one intervention (1.2%) focused on age
* 22 interventions (26.8%) looked at EDI in general.

It is worth noting that an individual intervention could cover more than one identity characteristic (in other words, these categories were not mutually exclusive) and as such these percentages do not add up to a total of 100. For example, nine interventions considered both gender and race, while another 19 interventions discussed EDI in general as well as a specific protected characteristic. An additional eight interventions examined three or more protected characteristics.

\begin{table}
\begin{tabular}{l c c} Area of EDI focus & No of Interactions & \\ Careers (recruitment, promotion, leave policies etc.) & 52 & 63.4 \\ \hline Culture and wellbeing (inclusion, experiences etc.) & 4 & 4.9 \\ Outreach and public engagement (community work, events etc.) & 2 & 2.4 \\ Data (equality monitoring, increasing disclosure etc.) & 2 & 2.4 \\ \hline Funding (scholarships, grant awards etc.) & 1 & 1.2 \\ Careers and culture combined & 4 & 4.9 \\ \hline Careers and outreach combined & 5 & 6.1 \\ Three or more areas covered & 5 & 6.1 \\ \hline Other & 3 & 3.7 \\ Other: general policy, practice or governance & 2 & 2.4 \\ \hline Other. access, retention and employability of students & 2 & 2.4 \\ \hline
**Total** & **82** & **100.0** \\ \end{tabular}
\end{table}
Table 3: Area of EDI focus 

#### 3.5.3 Area of EDI investigated and sector or disciplinary focus

The majority of interventions (52 out of 82 interventions or 63.4%) investigated aspects of an individual's career (for example, how they were recruited or the factors that influence applying for or taking up a post, or factors related to promotion or leave policies) (see table 3.3).

The majority of interventions (56.1% or 46 interventions) focused on EDI within the context of HE, research or STEM sectors. 12.2% (10 interventions) explored EDI in sectors related to business, management and leadership while only one considered aspects of education, teaching and learning and five looked at EDI issues in healthcare. None of the interventions focused on EDI within the creative arts or within a charity, a community or public services. Twelve interventions (14.6%) covered EDI in multiple sectors or disciplines, and eight (9.8%) did not apply to a specific sector or discipline.

#### 3.5.4 Relation to UKRI and the R&I landscape

The evaluation framework also aimed to identify how each intervention may contribute to UKRI's EDI policies and initiatives, and where these contributions would fit with regards to UKRI's membership organisations. The frequency of interventions across the different areas of UKRI's work is summarised in table 3.4.

#### 3.5.5 Type of intervention

As shown in table 3.4, a broad spread of EDI interventions were identified, with approximately one quarter evaluating changes to EDI strategy or policy. Notably, there were also 27 interventions (32.9%) that included more than one type (as defined in the framework).

#### 3.5.6 Methodology employed and data captured

For interventions citing empirical results, the evaluation framework extracted two key pieces of information related to the methodology: (i) what type of design was employed and (ii) what type of data was collected. The evaluation framework listed eight explicit types of study design as well as options for interventions that did not state a clear methodology, were not an empirical evaluation or were less frequently adopted methods in academic literature, such as national figures, audits, document or discourse analysis (summarised in table 3.6). Almost half of the interventions did not include sufficient information to categorise their methodology (45.1%). However, of those that did provide information on their method, a large portion included a mixed-methods design (roughly one out of four in the whole sample).

With regard to the type of data collected and analysed, the majority of interventions included either quantitative data (30.5% or 25 sources) or both qualitative and quantitative data (42.7% or 35 sources), with only one intervention relying on qualitative data only (1.2%). There were 21 interventions for which the type of data collected was unclear.

\begin{table}
\begin{tabular}{l c c} \hline Study Action & \multicolumn{2}{c}{No of} \\  & \multicolumn{2}{c}{Interactive} \\ \hline Within-groups or longitudinal & 2 & 2.4 \\ Between-groups or cross-sectional & 10 & 12.2 \\ \hline Time series analysis & 1 & 1.2 \\ \hline Case study (or case studies) & 3 & 3.7 \\ Qualitative analysis of interviews or journals & 3 & 3.7 \\ \hline Document analysis & 5 & 6.1 \\ Other quantitative analysis (such as analysis of sector or staff-level data) & 2 & 2.4 \\ \hline Other qualitative analysis (such as discourse analysis) & 1 & 1.2 \\ Mixed methods & 17 & 20.7 \\ \hline Conceptual article or not applicable & 1 & 1.2 \\ Unknown & 37 & 45.1 \\
**Total** & **82** & **100.0** \\ \hline \end{tabular}
\end{table}
Table 3.6: Study Action

[MISSING_PAGE_FAIL:18]

## Chapter 4 Previous workWhich organisations have previously reviewed and explored the key challenges for EDI in the UK research and innovation landscape?

### Overview

Advance HE identified 20 sources that reviewed or explored the EDI challenges in the R&I landscape (as presented in the bibliography). These sources were identified via the search of online databases and the targeted search of organisational websites, but were not included in the evaluation framework (for example, they did not present an empirical evaluation of an EDI intervention, they were published before 1 January 2011 etc.). This chapter reviews challenges discussed in these sources, organised primarily by protected characteristic, and concludes with a summary of themes explored and areas of research, innovation and EDI considered. As noted in section 2.2, sources are discussed in order to outline some key challenges that interventions were designed to address, rather than to provide a comprehensive account of all EDI challenges related to R&I. Sources reviewing and exploring EDI challenges that were not captured via this review's data collection methods, and are therefore omitted from this chapter, may nevertheless be of potential value to EDI researchers.

### Gender

Reviews by McKinsey and Company and the Women's Business Council provide high-level data on gender and the economic landscape in the UK. McKinsey and Company's Women Matter research series reviewed the position of women in the global workforce since 2007. Their report, _The Power of Parity: Advancing Women's Equality in the United Kingdom_ (2016), focused on gender equality in the context of the changing UK economy and future needs for productivity and growth. It identified that, while the UK has come a long way towards improving social and economic opportunities for women, inequalities remain in a number of areas. The report found that women:

* work in less productive sectors and are concentrated in lower-paid occupations, which affects their financial stability
* are least represented in high-productivity sectors, including STEM and higher-salaried occupations, skilled trades and managerial and leadership positions
* are most affected by inequality when they enter the workforce or take on a parenting role.

The Women's Business Council provides cross-sector benchmarking information on women in the UK workforce. Their report, _Maximising women's contribution to future economic growth_ (2018), highlighted improvements but also noted the continuation of gender issues:

* the employment rate for women increased from 68% in 2014 to 71% in 2018
* the UK's overall gender pay gap fell from 19.7% in 2013 to 17.9% in 2018
* women on FTSE 100 boards increased from 20.7% in 2014 to 30.2% in 2018
* women as a percentage of all self-employed people increased from 30.5% in 2014 to 33.2% in 2018.

#### 4.2.1 Women in STEM

Among the sources reviewed, several organisations presented annual data on the representation of women in STEM. The WISE Campaign publishes **annual statistics** on its website on women in the STEM workforce. In 2017, they highlighted some positive trends: for example, more women worked in core STEM (science, engineering, information and communications technology and skilled trades; health occupations are not included in the scope of core STEM) than ever before (61,430 more women worked in core STEM in 2017 than in 2016). However, women remained underrepresented in STEM industry, where they composed 23% of the workforce. The STEM areas with the greatest underrepresentation of women were engineering (11% women), information and communications technology (17% women), skilled trade (8% women) and management positions (15% women). Among science professionals, there was a better representation of women (42%).

Advance HE publishes annual staff statistical reports on the representation of women in STEM subject areas in HE. _Equality in higher education: staff statistical report 2018_ reported that, in 2016-17, 41.9% of science, engineering and technology (SET) academic staff were women. Subject areas with notably low proportionsof women included electrical, electronic and computer engineering (14.7% female academic staff) and mechanical, aero and production engineering (17.1% female academic staff). Subjects with notably high proportions of female academic staff were nursing and allied health professions (74.9% female academic staff) and psychology and behavioural sciences (60.8% female academic staff).

Lastly, the Royal Academy of Engineering's _Diversity and Inclusion Progression Framework engineering and science professional body benchmarking report_ (2017) provided EDI data on staff and members of professional engineering institutions (PEIs) and scientific bodies. While the majority of the PEIs and scientific bodies had a workforce that was more than 50% female, on average women comprised 13% of PEI membership and 34% of scientific bodies' membership.

#### 4.2.2 The leaky pipeline

The Royal Society of Edinburgh's _Tapping all our talents_ reports (2012, 2018) set out key challenges related to gender in STEM careers in Scotland. The 2012 report emphasised the high attrition rate of women employed in the STEM sector and identified the problem of the 'leaky pipeline': although Scottish universities educate large numbers of women in STEM, 73.0% of female graduates leave the sector compared to 48.0% of male graduates. In academia, women were lost in larger proportions than men at every step of the postgraduate ladder and were under-represented in top positions across academia, business and the public sector.

Survey results from _ASSET 2016: experiences of gender equality in STEM academia and their intersections with ethnicity, sexual orientation, disability and age_ (ECU, 2016) revealed a number of factors that inhibited the progress of women in STEM careers, such as:

* the inequitable allocation of tasks and resources, which related to professional development and markers of esteem, between men and women
* a finding supported by national HE statistics, which showed that in 2016-17 31.1% of female academics were on teaching-only contracts compared to 23.8% of male academics (Advance HE, 2018).

Women and innovation

WISE Making a Difference - why women in STEM doesn't laboratory (2016)

_"Historically, women have played a significant role in building and creating new innovations across all sectors - but somewhere along the line, something changed."_

This collaboration between the WISE Campaign and Amazon involved research that conducted 50 semi-structured interviews with women from 28 companies and gathered 1,202 survey responses.

Key findings included the following:

* nine out of ten women experienced barriers to their STEM career and more than a quarter (26%) experienced more barriers than enablers
* two thirds of women who worked in the UK's innovation economy had overcome challenges on their own to succeed in their careers and just over one in five women (22%) said they had received support from their employers
* the top three barriers reported for women working in STEM were a lack of confidence (84%), adaption to a male-pipeline': although Scottish universities educate large numbers of women in STEM, 73.0% of female graduates leave the sector compared to 48.0% of male graduates. In academia, women were lost in larger proportions than men at every step of the postgraduate ladder and were under-represented in top positions across academia, business and the public sector.

Survey results from _ASSET 2016: experiences of gender equality in STEM academia and their intersections with ethnicity, sexual orientation, disability and age_ (ECU, 2016) revealed a number of factors that inhibited the progress of women in STEM careers, such as:

* the inequitable allocation of tasks and resources, which related to professional development and markers of esteem, between men and women
* a finding supported by national HE statistics, which showed that in 2016-17 31.1% of female academics were on teaching-only contracts compared to 23.8% of male academics (Advance HE, 2018).

Women and innovation

WISE Making a Difference - why women in STEM doesn't laboratory (2016)

_"Historically, women have played a significant role in building and creating new innovations across all sectors - but somewhere along the line, something changed."_

This collaboration between the WISE Campaign and Amazon involved research that conducted 50 semi-structured interviews with women from 28 companies and gathered 1,202 survey responses.

Key findings included the following:

* nine out of ten women experienced barriers to their STEM career and more than a quarter (26%) experienced more barriers than enablers
* two thirds of women who worked in the UK's innovation economy had overcome challenges on their own to succeed in their careers and just over one in five women (22%) said they had received support from their employers
* the top three barriers reported for women working in STEM were a lack of confidence (84%), adaption to a male-pipeline': although Scottish universities educate large numbers of women in STEM, 73.0% of female graduates leave the sector compared to 48.0% of male graduates. In academia, women were lost in larger proportions than men at every step of the postgraduate ladder and were under-represented in top positions across academia, business and the public sector.

Survey results from _ASSET 2016: experiences of gender equality in STEM academia and their intersections with ethnicity, sexual orientation, disability and age_ (ECU, 2016) revealed a number of factors that inhibited the progress of women in STEM careers, such as:

* the inequitable allocation of tasks and resources, which related to professional development and markers of esteem, between men and women
* a finding supported by national HE statistics, which showed that in 2016-17 31.1% of female academics were on teaching-only contracts compared to 23.8% of male academics (Advance HE, 2018).

Women and innovation

WISE Making a Difference - why women in STEM doesn't laboratory (2016)

_"Historically, women have played a significant role in building and creating new innovations across all sectors - but somewhere along the line, something changed."_

This collaboration between the WISE Campaign and Amazon involved research that conducted 50 semi-structured interviews with women from 28 companies and gathered 1,202 survey responses.

Key findings included the following:

* nine out of ten women experienced barriers to their STEM career and more than a quarter (26%) experienced more barriers than enablers
* two thirds of women who worked in the UK's innovation economy had overcome challenges on their own to succeed in their careers and just over one in five women (22%) said they had received support from their employers
* the top three barriers reported for women working in STEM were a lack of confidence (84%), adaption to a male-dominated environment (75%) and lack of recognition from senior management (72%).

The research also found that, in conversations about innovation, women do not readily self-identify with the term 'innovator' (only 4.7% considered themselves 'innovators'). The report recommended changing the language used to discuss innovation, which might positively impact the perception of women and girls and attract greater diversity to the innovation sector.

#### 4.2.3 Research grants

Grants are an important aspect of a researcher's career development. The Wellcome Trust has conducted two EDI reviews on this subject.

_Diversity in grant awarding and recruitment at Wellcome_ (Bridge Group, 2017) identified some of Wellcome's EDI issues, which included:

* on average, a lower success rate for female grant applicants than for male applicants
* women requesting smaller grant sums than men
* a large proportion of missing data on grant applicants' ethnicity and a low disclosure rate for disability (2.0%).

_Review of diversity and inclusion literature and an evaluation of methodologies and metrics relating to health research_ (Chambers et al., 2017) also noted several gender-related studies, such as Head et al. (2013), that investigated funding awarded to UK institutions for infectious disease research between 1997 and 2010. The study found that men received 78.5% of all funding and that the mean award value was higher for men. Bedi et al. (2012) also reported that women received smaller grants than men in Wellcome Trust awards. Sidhu et al. (2009) used data from the 2006 Athena Survey of Science, Engineering and Technology (ASSET) and noted that female respondents who were parents or had caring responsibilities were less likely than male respondents to have publications as sole and joint authors.

The Biotechnology and Biological Sciences Research Council (BBSRC) has also published a review of female academics' success rate in grant applications. _Towards a better understanding of issues affecting grant applications and success rates by female academics_ (2015) was based on research conducted with eight HEs. It found that the proportion of grant applications from women remained relatively constant during the period surveyed (between 21.0% and 23.0%). Success rates for men and women varied: men had slightly more success overall than women (the success rate for men reduced to 27.0% in 2014 from 31.0% in 2011; the rate for women reduced to 24.0% in 2014 from 26.0% in 2011).

### Disability

_Getting things changed_ (2018), funded by the Economic and Social Research Council (ESRC) and led by the University of Bristol, presented findings from a review of barriers for disabled people.

across various types of organisations. The report found that the introduction of the Equality Act 2010 had not fully addressed disabling barriers within institutions such as hospitals and universities.

Advance HE's annual staff statistical report provides national figures on the proportion of HE staff who disclosed as disabled. Of particular note for the research sector, is that while it has increased over recent years, disability disclosure among academics remains low (4.1% in the 2016-17 academic year) and was even lower among staff on research contracts (3.0%) compared to staff on teaching contracts (5.2%).

#### 4.3.1 Mental health

Mental health issues are protected under the characteristic of disability in the Equality Act. _Seizing the momentum_ (Business in the Community (BITC), 2018) noted that, although awareness and action on mental health at work has increased in recent years, evidence suggests that mental health issues remain a key challenge. It found that:

* 61% of employees have experienced mental health issues due to work or where work was a related factor
* 64% of managers have, at some point, put the interests of the organisation above staff wellbeing
* 54% of employees felt comfortable talking about general mental health issues in the workplace

The Wellcome-funded review _Understanding mental health in the research environment: a rapid evidence assessment_ (Guthrie et al., 2017) provided contextual information on mental health in research careers. It noted that the majority of university staff found their job stressful, with levels of burnout higher among university staff than among the general working population. The experiences of academics were comparable to those 'high-risk' groups such as healthcare workers. A large proportion of postgraduate students (over 40.0%) reported symptoms of depression, emotional or stress-related problems, or high levels of stress.

### Race and ethnicity

BITC have explored the experience of black, Asian and minority ethnic (BAME) people in the workplace.

_Race at work_ (2015) identified workplace issues that were relevant for those working across the R&I landscape, such as:

* racial harassment and bullying within the workplace were still prevalent
* BAME employees were less satisfied with their experiences of management and progression than white employees and were less likely to feel part of a team
* BAME employees lack role models inside and outside of the workplace.

_Race to Progress_ (BITC, 2011) identified specific issues for the career progression of BAME employees, such as fewer promotion opportunities during their career than white colleagues, a lack of support, poor relationships with management and racial discrimination.

In relation to barriers experienced by black and minority ethnic (BME) staff in the HE sector, ECU has published _Experiences of Black and Minority Ethnic Staff in HE_ (2011). This research, conducted by the Centre for Higher Education Research and Information at the Open University, found that BME staff were less likely than non-BME staff to be in leadership and management positions within institutions. The research also noted a difference between BME staff from the UK and international staff (both BME and non-BME). For example, UK BME staff were less likely to write academic papers that contained research findings or serve as a peer reviewer than non-BME staff or international BME staff. Additionally, the majority of the study's BME research participants had personally experienced the damaging effects of subordination or exclusion because of their race.

#### 4.4.1 Progression from undergraduate to postgraduate study

Two reviews of this theme, related to EDI, were identified and both revealed challenges related to race. _Widening participation from undergraduate to postgraduate research degrees: A research Synthesis_ (Wakeling & Kyriacou, 2010) and _Diversity in grant awarding and recruitment at Wellcome_ (Bridge Group, 2017) identified differences in entry to doctoral study by ethnicity and socio-economic status. The reviews suggested possible reasons for these differences, including subject studied, institution attended and attainment at first degree level (which were not evenly distributed across ethnicity and socio-economic status).

### Sexual orientation and gender reassignment

BITC recently published _Working with pide: Issues affecting LGBT+ people in the workplace_ (2019). The report found that lesbian, gay, bisexual and trans (LGBT+) people still experienced high levels of discrimination in the workplace and significant inequalities, especially in the areas of mental health and wellbeing. Nearly three quarters of LGBT+ people surveyed (74%) had experienced mental health problems related to their work. The experience of mental health issues was a third higher among LGBT+ employees than among straight/cis employees, with younger LGBT+ employees particularly vulnerable in this respect.

Employee data on sexual orientation and gender reassignment is incomplete. The HE sector has made some progress in this area. In 2016-17, gender reassignment data was unknown for more than two in three HE staff (66.5%). While large, this proportion has dropped by 2.5% since 2015-16 (when data was unknown for 69.0% of staff). Sexual orientation data was unknown for 49.5% of staff in 2016-17. This is also a drop in unknown data of 4.2% since 2015-16. We further explore issues regarding data collection and disclosure in chapter 7.

_The experience of lesbian, gay, bisexual and trans staff and students in higher education_ (ECU, 2009), research conducted by Professor Gill Valentine and Dr Nichola Wood (both University of Leeds) and Professor Paul Plummer (University of Calgary), found that some LGB staff were concerned about being out because of employment security, discrimination and anxieties that identifying as LGB might compromise their research. LGBT staff reported experiences of discrimination such as systematic institutional discrimination and implicit discrimination in areas related to promotion, discretionary pay rises and redundancies. 23.0% of trans staff and 4.2% of LGB staff reported being denied a promotion due to their trans status or sexual orientation. LGB staff noted high levels of negative treatment, because of their sexual orientation, from colleagues, students and others working in their HEI.

### Chapter summary

This chapter has presented EDI challenges reported by a range of organisations and has discussed several themes related to EDI in R&I, including:

* employment and career trajectories
* areas of occupational segregation
* experiences and barriers in the workplace
* progression from undergraduate to postgraduate study
* access to research grants
* data collection and disclosure.

#### 4.6.1 EDI gaps

Among sources reviewed, gaps that might warrant future work were also identified.

* **Innovation:** only one source specifically related to innovation (WISE and Amazon, 2019). All other sources discussed general careers or research and academic careers, with a clear focus on the HE sector. While Innovate UK has recently commissioned a review of EDI in innovation in the international landscape (Klingler-Vidra, 2019), this review has found very few published works on EDI in innovation in the UK landscape.
* **Protected characteristics:** gender, in particular women, were the focus of most reviews of EDI challenges in the R&I landscape. Among these works on gender, women in STEM was the predominant topic.

Other sources discussed in this chapter were on race, disability, sexual orientation and gender reassignment. Very few sources looked specifically at age, religion and belief, or pregnancy and maternity. A recent increase in works on disability appears to focus on mental health.

Socio-economic status was only discussed in two sources and was not the primary focus of these works. This suggests a gap in knowledge related to this characteristic in the R&I sectors. We should note that socio-economic status was the focus of a great deal of widening participation literature, but it was agreed with UKRI and the Advisory Group that this was out of the scope of this review.

Finally, sources did not discuss intersectionality, with the exception of some consideration in Advance HE's annual statistical reports.

* **Geographic focus:** the majority of sources discussed had a UK-wide focus. However, Advance HE's annual HE statistical reports disaggregate some data tables by devolved nation. _Tapping all our Talents_ (Royal Society of Edinburgh, 2012 and 2018) considered the specific national context in Scotland. No sources considered contextual differences in Northern Ireland and Wales.

\begin{table}
\begin{tabular}{|p{113.8pt}|p{113.8pt}|p{113.8pt}|p{113.8pt}|} \hline Recommarding from the creation & Policy & Future & Employee & Research \\ \hline Among sources reviewed, reviews of EDI challenges most often focused on research, in particular in HE and STEM contexts. This would suggest a need for further research on EDI challenges in innovation. & & & \\ \hline Reviews of EDI challenges most often focused on gender, in particular women. This would suggest a need for further research on EDI challenges related to the other protected characteristics and socio-economic status. & & & \\ \hline Sources reviewed did not discuss intersectionality. Future research should therefore consider how the intersection of identity characteristics affects EDI challenges and their impact. & & & \\ \hline \end{tabular}
\end{table}
Table 4.1: Summary of recommendations from previous work

## Chapter 5 What works?Among interventions that have been implemented by organisations comparable to UKRI, which have proven effective, or less effective, and why?

#### 5.1.1 Types of intervention

The evaluation framework allowed us to categorise interventions across different types (and their subtypes, where applicable). Findings are therefore organised by intervention type, with examples to highlight interventions that were effective and less effective (where possible) within each type as below.

* training (e.g. diversity and unconscious bias).
* strategies, policies or processes (e.g. funding, recruitment and career breaks).
* career development programmes (e.g. mentoring and leadership development).
* recognition schemes (e.g. charters and awards).
* employer engagement and outreach (e.g. networks and student outreach).

Some of the sources discussed an intervention or bundle of interventions that related to more than one 'type' of intervention.

#### 5.1.2 Effectiveness

The outcomes reported by an intervention were understood to be the primary indicator of its effectiveness. Our interpretation of outcomes encompassed both quantifiable outcomes, such as statistical information on applicant numbers in a recruitment process, and outcomes related to perceptions or experiences, such as reported changes in awareness, understanding or confidence. Interventions that did not report any intended or unintended outcomes were not highlighted as examples of effective interventions. To provide further contextual information on interventions' effectiveness and ineffectiveness, self-reported information from sources on reasons for successes and failures of interventions was also extracted and analysed.

#### 5.1.3 Comparability to UKRI

As far as possible, examples are included from organisations comparable to UKRI in their functions or interests. To address the over-representation of interventions included in the evaluation framework that focused on gender (31.7% of interventions reviewed, see section 3.5.2), where possible, examples that focused on protected characteristics other than gender are foregrounded.

### Training or development

Twenty-one interventions mentioned EDI-related training. Training was typically an aspect of a broader intervention. We found the following types of training interventions:

* **diversity training:** organisation-led seminars or training sessions for employees or students to enhance cultural sensitivity and awareness of diversity-related issues
* **unconscious bias training (UBT)**: a session, programme or intervention in which participants learn about unconscious bias, typically with a view to reducing the negative impact of bias on organisational practice and individual behaviour
* **EDI capacity development:** diversity-related training aiming to equip organisations with knowledge necessary to improve EDI.

The first two are discussed here and the last is discussed in section 5.6 as these interventions typically related to employer engagement and outreach.

#### 5.2.1 Diversity training

The review found six interventions that focused on diversity training. Interestingly, all interventions focused on particular aspects of diversity or particular audiences. Two worked with employees and focused on race equality issues (Advance HE, 2018; King et al., 2018), three targeted students and related to EDI in general (Glasgow Caledonian University, 2019 a, b; RSE, 2018) and one targeted leaders and focused on respect and inclusion (CMI, 2018).

The two race training interventions, designed for an employee audience, are worthy of note as they reported some measurable impact. The review by King et al. (2012) examined diversity training provided at multiple NHS healthcare providers, representing 155,922 participants, to determine the effect of diversity training programmes on ethnic discrimination. In addition, the review considered the implications of organisational ethnic discrimination for individual job satisfaction in organisations that vary with regard to ethnic composition. The training offered varied between providers, but it generally involved one or two trainers and 20-30 trainees and lasted for four to 10 hours. Overall, the research suggested that diversity training can have a positive effect on individuals and organisations by reducing the likelihood that ethnic minorities experience discrimination. The authors suggested that, despite evidence that the effects of diversity training were not uniformly positive and that a backlash can occur, diversity training can help address EDI challenges within an organisation.

Advance HE (2018 d) received some positive results from its race equality training programme delivered in the HE sector. This programme included two full-day sessions and used a variety of methods including self-reflection, independent reading, participative exercises, presentations, videos and quizzes. Results showed significant improvements in participants' familiarity with seven of the 10 items covered in a race equality questionnaire (including critical race theory, deficit approach, institutional racism, intersectionality and intersectional, micro-aggression, race and white privilege). This suggests the efficacy of this training in teaching participants about race equality. However, the degree to which participants' confidence in engaging with race equality improved tended to be quite small and was, for the most part, not statistically significant. This suggests the training was less effective in enabling participants to engage with and take action on race equality.

#### 5.2.2 Unconscious bias training

The review found just one eligible source focused on UBT, which was a review of impact (Atewologun et al., 2018) published by the Equality and Human Rights Commission. It evaluated 88 sources published since 2013 against the following outcomes:

* awareness raising (explicitly noted in 11)
* implicit bias change (explicitly noted in 11)
* explicit bias change (explicitly noted in nine)
* behaviour change (explicitly noted in 10, although only two reported change).

The authors concluded that UBT was likely to increase awareness of and reduce implicit bias, specifically when training used implicit association tests and educated participants on unconscious bias theory. Additionally, the efficacy of UBT increased when the length of training was longer rather than shorter, when attendance rates were higher or it was mandatory, and when it was part of a broader organisational diversity strategy. However, the review also noted that evidence to demonstrate UBT's ability to change behaviour was limited because most available evidence did not adopt valid measures of behaviour change. They also cautioned about the potential for back-firing effects when participants were exposed to information that suggested stereotypes and biases were unchangeable.

## 6 Summary

Anore context is the role of training interventions that impacted the model efficacy of trained on race equality assessment. The impact mostly related to existing participants' awareness and tracking that understanding the impact of changes in addressing race equality and impact the performance of the model to extend evaluation to other forms of learning and dominance estimation.

To test the impact of different methods for training and dominance estimation, to test larger confidence of training on

Figure 17: A comparison of the results of the model to extend evaluation to other forms of learning and dominance estimation.

### Strategies, policies or processes

The development of strategies, policies or processes that support EDI was a recurrent theme across the sources, with 26 involving some form of new or revised strategy, policy or process. Four types of intervention relating to strategies, policies or processes stood out from this overarching theme:

* **national funding-related**
* **employee recruitment**
* **family friendly**
* **career break.**

#### 5.3.1 National funding-related strategies and processes

Of relevance to the UK research context are the Research Excellence Framework (REF) 2014 equality and diversity requirements and accompanying processes. These included requirements for institutions to produce a code of practice, conduct an equality impact assessment and processes for submitting staff with fewer research outputs where individual circumstances had affected their output. Several equality impact assessments were identified via the online database search. However, no equality impact assessments satisfied our inclusion criteria (for example, by including some measurement of outcomes) and were therefore not analysed using the evaluation framework.

The efficacy of REF 2014 requirements is the subject of two sources: the REF Equality and Diversity Advisory Panel (EDAP) report (2015) and a Call for Evidence response from Heriot-Watt University (Heriot-Watt University, 2019 c). The former reported that REF 2014 had a far-reaching impact on EDI, while Heriot-Watt University's response provided institution-level evidence of this impact. Overall, EDAP reported that the measures supported the inclusion of a wider pool of individuals who might have previously been excluded. The proportion of staff submitted to the REF with circumstances increased to 29.2% since the the Research Assessment Exercise (RAE) 2018 RAE 2008. EDAP concluded that the more systematic approach to output reductions was a positive step towards improved EDI in the sector. Heriot-Watt University reported that the REF 2014 processes helped raise the profile of EDI issues at the institution and led to a strategic investment in processes related to the Athena SWAN Charter.

Another notable EDI intervention from a UK funding body was the Scottish Funding Council's (SFC's) Gender Action Plan and its links to institutional Outcome Agreements (RSE, 2018). In August 2016, SFC published the plan, with strategic ambitions for both colleges and universities to tackle all forms of gender imbalance and the aim that no college or university course will have a gender imbalance of 75:25 or worse by 2030. From the academic year 2016-17, they embedded their plan within the annual Outcome Agreements they negotiate with Scotland's colleges and universities. This approach linked institutional funding to their progress achieved on gender equality. This powerful funding lever has resulted in a commitment from every college and university to:

* deliver on gender equality within institutional Outcome Agreements
* publish an institutional gender action plan, which includes proposed actions
* identify how they will build capacity for action and monitor progress.

These plans are in their early days of delivery and whether this intervention has been effective in achieving its aims remains to be seen.

#### 5.3.2 Recruitment policies and processes

Amending recruitment policies or processes to further EDI was the prime focus of six interventions. They discussed BME individuals in the police (Behavioural Insights Team (BIT), 2015), female academics (University of Nottingham, 2019 b), diversification of fellows (University of Nottingham, 2019 a) and female university governors (ECU, 2015 a).

The most robustly evaluated of these interventions was a randomised control trial (RCT) conducted by the BIT (2015). This aimed to identify a method to address the disproportionate drop in BME applicent success in the Situational Judgment Test component of the online recruitment process for one police constabulary. The intervention involved adding a few sentences to the emails received by a treatment group of 1,593 applicants (both BME and white), which hoped to prompt applicants to reflect on why they would be a good addition to the force. A control group received an unchanged email. The intervention positively affected outcome measures for BME applicants but had no effect on non-BME applicants. On average,BME applicants in the treatment group scored five points higher. The report suggested that this intervention was effective because it encouraged applicants to imagine themselves as a police officer and go with their gut instinct when answering questions, rather than with the 'correct' answer they felt they were expected to give.

While not subject to the same level of evaluation, the University of Nottingham's academic staff recruitment intervention took a multi-pronged approach. The Faculty of Engineering, in partnership with consultants Diversity by Design, piloted this innovative approach for the recruitment of two academic roles. Changes included:

* rewriting recruitment marketing materials to improve inclusivity
* CVs were not considered as part of the shortlisting process
* candidates' biographical details were removed
* candidates were not requested to attend any 'informal' assessments before the assessment.

Both pilot recruitment processes reported success and led to the appointment of two high-quality female candidates. The project report suggested a key element in this success was the elimination of bias at each stage of the recruitment process, basing decision making on firm evidence and the use of predetermined criteria.

#### 5.3.3 Fellowships and recruitment

Broadly speaking, fellowships are academic research positions at universities or research institutions, usually at the postgraduate or postdoctoral level, which include monetary awards connected to work in a specific field. While not a common theme among the interventions, the examples submitted to our Call for Evidence by the University of Nottingham deserve note as they emphasised the recruitment of diverse fellows and reported impact (University of Nottingham, 2019 a). This included its Anne McLaren Fellowships, for female researchers in STEM, and Nottingham Research Fellowships, for early-career researchers across all academic disciplines.

Both offered an attractive package of support, which included three years' funding to conduct research, career development opportunities, relocation expenses and additional childcare costs, up to E5,000 per annum. The university committed to a gender balance for appointment of fellows and ensuring the schemes attracted a diverse range of applicants. Monitoring data revealed evidence of the efficacy of these schemes. For the Anne McLaren Fellowships, a gender balance has been maintained since 2017 (as of 2019, 55% of fellows were women) and the racial diversity of fellows has been good (16% were BAME).

The university reported that a large part of the schemes' successes came from how they were advertised. In particular:

* carefully constructed advertisements were used to promote fellowships to a diverse range of applicants; this included the use of gender decoding tools to check the language for gender inclusivity
* images used in promotional materials were reviewed to ensure that they represented actual fellows and the diversity of their cohort
* examples of the current cohort of fellows were shared, with descriptions of their experience, ambitions and what they have gained from the schemes.

As with Athena SWAN submissions and grey literature, Call for Evidence responses included self-reported judgments as to reasons for the successes and failures of an intervention. Rather than question the level of confidence we can have in the information presented, the value of this information comes from what it says in regard to what the authors of Call for Evidence responses perceived as reasons for successes and failures.

#### 5.3.4 Governor recruitment

Three university governor recruitment interventions were reported by one source in our dataset (ECU, 2015 a). In terms of effectiveness, two institutions reported statistical information on the gender breakdown of applicants for governor vacancies (following work to increase the diversity of applicants). They showed modest increases: female applicants increased from 10.0% to 15.0% at one HEI and, at another HEI, nine of 33 applicants were women. However, an increase in female applicants and any resultant appointments of women did not necessarily result in an improvedgender balance on the university boards, as female governors also left boards when their terms came to an end. Nevertheless, these interventions suggested that positive impacts can come from interventions even when overall gender balance has not changed. To support this point, positive qualitative outcomes were also reported that noted increased awareness of the need to diversify governing bodies and increased engagement with EDI among governors. Although these examples relate to the recruitment of governors in HE, the experiences discussed would likely relate to EDI on boards in general.

#### 5.3.5 Family-friendly policies

Eleven interventions related to this theme, which covered a wide range of policies and facilities for parents. Interestingly, most of these interventions were responses to the Call for Evidence, which perhaps indicates that these unpublished interventions lent themselves to this data collection method.

Six interventions from the Call for Evidence involved the provision of family-friendly facilities or policies that support staff or student parents to access professional development opportunities. These included: financial assistance with childcare for staff and students to attend continuous professional development (CPD) opportunities; an on-site nursery; and a student parent study space.

Efficacy of these interventions was generally conveyed in terms of quantitative measures related to uptake. For example, the John Innes Centre reported that its Family/Dependant Support Fund, which pays for childcare so staff can participate in CPD opportunities, has been used 15 times since its establishment in 2013.

The University of Glasgow's Student Study Space (University of Glasgow, 2019 c) presented a more rigorous evaluation of their intervention. They reported 322 separate family usages of the lounge between 16 July and 30 November 2018. Additionally, feedback received has been extremely positive, with other HEIs across the UK keen to implement a family study space for the benefit of their students. The reported efficacy of this intervention related to collaboration across the university.

#### 5.3.6 Career break policies

The John Innes Centre returned four interventions related to career breaks (John Innes Centre, 2019 a-d). These included:

* **the Parent Carer Fund**, which pays for a postdoctoral research associate (or equivalent) to cover up to one year's leave or institutional support for the extension of a fixed-term contract following parental leave
* **the Stop the Tenure Clock initiative**, which allows staff to request an extension of up to one year to the five-year tenure track process per event or circumstance (for example, childbirth, adoption, extended periods of shared parental leave, severe personal illness and caring responsibilities).

As noted in relation to family-friendly policies, the effect of these policies was demonstrated using data on uptake.

Finally, BIT's _Return to work: parental decision making_ (2018) highlighted ways to increase the uptake of shared parental leave (SPL) policies among men. The source reported results from two RCTs that tested whether 'behaviourally informed' or'simplified' messages changed behaviours related to shared childcare among fathers. While the 'behaviourally informed' messages had no overall impact on engagement or interest in SPL or flexible working, it did demonstrate an impact on participants who currently had children.

A second test found that the provision of'simplified' information to prospective parents improved comprehension of the scheme and reduced the perceived effort related to take-up. BIT's findings suggest that'simplified' messages, tailored for target audiences, could increase the take-up of SPL and/or flexible working among men.

### Career development programmes

Career development programmes were a common focus among the interventions reviewed. Sixty-seven interventions related to this theme. This section shares examples of specific programmes focused on:

* mentorship or sponsorship women returners professional or leadership development.

#### 5.4.1 Mentoring and sponsorship

Employee mentorship programmes emerged as a common career development intervention used to support EDI. A total of 12 interventions in our database included mentoring or sponsorship. Seven of these focused on mentoring or sponsorship; within this group, five were designed for women (ECU, 2012 b; CMI, 2018), one targeted disability and race (ECU, 2017) and one encompassed general EDI (Guiccione, 2018).

Despite the high prevalence of this intervention type in this review, few sources presented an empirical investigation of the effectiveness of mentorship or sponsorship programmes. The only review of multiple mentoring schemes identified was _Mentoring: progressing women's careers in higher education_ (ECU, 2012 b). This research was conducted by Professor Joyce Quinn at Plymouth University and reported on four schemes for women in the HE sector. While the report acknowledged that it is difficult to disaggregate the impacts of mentoring from other factors, the case studies showed some positive results. For example, at Queen's University Belfast, mentees had:

* applied for more senior posts attended training courses participated in national and international networks
* taken a greater interest in other equality initiatives.

The report concluded that key factors for determining the success of mentoring schemes were:

* institutional support matching and training participants monitoring and evaluation well-defined programme goals, expectations and roles.

Factors that limited the efficacy of such schemes included:

* adequate time and space for mentoring unrecognised addition to workload incompatibility of mentoring pairs lack of commitment from the institution.

The Aspire Mentoring Programme, delivered by the Open University (HEFCE, 2017), focused on disability and race. This programme involved a nine-month mentoring relationship for staff at any grade who self-identified as ethnic minority or disabled (or both). The university reported that, of the approximately 50 staff who completed the programme, one fifth believed it was key to their success in moving to more senior roles. Many also reported increased recognition and responsibilities in their current role. Additionally, institutional staff survey results showed improvements in satisfaction levels among ethnic minority and disabled staff. The extended timeframe, longer than most other mentoring schemes reviewed, may be a factor in its success.

An alternative approach was found in the finance sector. BlackRock implemented formal executive sponsorship to support the advancement of women (CMI, 2018). BlackRock matched each participant with an executive sponsor who was a member of the Global Executive Committee and worked in a different area of the business. Training was provided for both the sponsor and the participant.

Results from the executive sponsorship programme were promising: more than 80.0% of participants moved into new or expanded roles after completion of the programme. The source suggested that the matching of executives with women from different areas of the business was key to its success, as this created a two-way exchange whereby the participant learnt from the executive and the executive gained market insights and knowledge from the participant.

#### 5.4.2 Returner programmes

Three interventions presented insights into the efficacy of returner programmes in the R&I context. The term'returnship' was first trademarked by Goldman Sachs in 2008 (Goldman Sachs, 2019) and returner programmes have since grown in popularity, though they remain rare outside private sector organisations. Within this sector,'returns' are usually professional, fixed-term contracts that are paid and at a relatively senior level. An alternative approach is'supported hire' programmes, which offer the possibility of a permanent position.

Women Returners Scotland was the only intervention that discussed'returnships' in this sense (Equate Scotland, 2016). This six-month pilot supported women to return to work in the STEM industries after a career break. It was delivered by Equate Scotland and Prospect, the trade union for professionals, and funded by Skills Development Scotland. The project worked with a group of 15 women and six STEM employers in Scotland and provided:

* a structured support programme for returners to build their confidence and develop skills
* active assistance for employers to create and fill'returnships' (paid work placements) that lasted between three and six months. Evaluation of the project shared quantitative and qualitative indicators that demonstrated the pilot's impact and included:
* seven retumship interviews
* two jobs secured
* four paid retumships
* high levels of engagement with the participants and good engagement with employers
* returners reporting improved confidence and valuable learning on practical issues related to returning to work.

While successful overall, Equate Scotland described the challenge of project timescales, with some employers unable to engage at the pace demanded.

Two interventions discussed the operation of returner programmes in the context of HE research. These differed from the conventional sense of returner programmes as they focused on university staff rather than those seeking employment following a career break. The University of Glasgow's Academic Returners Support Fund (University of Glasgow, 2019 a) invited staff who had taken parental leave to apply for up to E10,000 to support their research (for example, teaching cover, conference attendance, skills development).

The university reported that around 30 applications had been granted since 2015, with examples of individual impact gathered from those awarded funding. It is too early to say if the initiative had an impact on parental promotion or progression as this would require a long-term study of impact.

The University of Sheffield ran a similar scheme, the Women Academic Returners' Programme, and was able to report long-term impact as it has run for over 10 years (HEFCE, 2017). The scheme enabled women to request up to E10,000 to support an additional post or up to E5,000 to support other research-related activities, such as conference costs, coaching and training courses. The scheme was open to female academics and researchers across all faculties. Since 2006, over 136 women have received awards that total over E1.7 million. Award recipients have since brought in over E12.5 million in apportioned research grant income to the university, which representsa return on investment of over 620%. The university also saw improved retention rates for women who returned after maternity leave.

#### 5.4.3 Professional development programmes

The review located three examples of professional development programmes that operated in the R&I context, Aditi (Yelkin, 2018), Aurora (Bamard et al., 2016) and SUSTAIN (Academy of Medical Sciences, 2017). The first programme focused on BME individuals, while the other two focused on women. Evaluations of the Aditi and Aurora programmes, which are both leadership development programmes, help shed light on their efficacy.

The University of Birmingham ran Aditi as a pilot project to support the personal development of aspiring BME leaders at the university. The six-month programme involved a mixture of learning sessions and completion of a personal project. Participants were also provided with a coach who used findings from a 360 degree feedback tool to facilitate personal development. The evaluation reported that 12 BME staff members completed the pilot. These individuals reported personal impacts such as:

* increased levels of confidence and competence
* improvement in the managerial aspects of their roles
* feeling involved in the strategy and culture of the university.

The report authors highlighted formal consultation with participants during the programme design as a reason for its success. They suggested that this helped establish a clear idea about an individual's barriers to progression, enabled participants to take ownership of the programme and created a sense of collaboration and cohesion. Long-term impacts from the programme are yet to be seen.

Aurora, a women-only leadership development programme targeted at women up to senior lecturer level or professional services equivalent working in a university, college or related organisation, was evaluated using longitudinal mixed-methods research, discussed in more detail in chapter 6. The evaluation found that Aurora participants were more likely to seek and gain promotion and to have taken steps towards leadership responsibilities than female colleagues who had participated in the programme. The study also elucidated reasons why Aurora has impacted women's careers. It noted that Aurora stimulated women's engagement in greater career self-management activity, such as engagement in mentoring, making themselves more visible to others who could help their career, seeking out new contacts, seeking career goals and asking others for feedback.

### Summary

Although a common intervention type, potentially in addition to round errors, the sources ordered the bad knowledge after evidence of the impact of membership in the R&I context, the subject the need for longitudinal evaluations to determine the degree of the target. The impact of interaction strengths across a wide variety of knowledge in the corporate sector and could potentially be transferred to other risk products.

Identifying for venue needs to directly make interaction within the R&I context and have presented promising results.

Lostership development culture for groups who already picked characteristic laws, the elements to send-feature results.

As with previous reactions, gender to hit replacement or to leave within career, development programmes in the R&I language, 2777-17.

### Recognition schemes

Recognition schemes recognise and celebrate organisations' good practice and progress made to advance EDI. The review identified five recognition schemes: two focused on general EDI (Heriot-Watt University, 2019 b; Tech Talent Charter, 2019) and two focused on gender (ECU, 2014; Institute of Physics, 2013).

The Tech Talent Charter stood out within the tech sector. This charter involved an organisational commitment to deliver greater diversity in the UK's tech workforce. The charter's benchmarking report shared indicators of efficacy in the promotion of EDI in the sector (Tech Talent Charter, 2019). For example, the majority of charter signatories have introduced diversity policies and the representation of women is higher among charter signatories than in other tech companies.

Two major HE gender equality awards schemes, Project Juno and the Athena SWAN Charter,

[MISSING_PAGE_FAIL:34]

* provide retention and progression with the same resources as recruitment and outreach
* have confidence in implementing positive action measures.

The project evaluation report noted that 100% of survey respondents had more confidence in taking positive action and several case studies reported changes in understanding and confidence.

One source, from Fuertes et al. (2013), delivered a programme with six Scottish small and medium-sized enterprises (SMEs) designed to build capacity to address age management issues. The programme provided a two-hour age management workshop for managers and HR personnel, as well as tailored brochures that contained feedback on organisational policies and practices related to age diversity. The programme achieved mixed results. In terms of attitudes, overall perceptions of older workers' capabilities changed. In terms of policy and practice, two companies changed, or intended to change, aspects of their recruitment practices. However, there was no evidence that participants departed from practices and policies that related to part-time and flexible working.

#### 5.6.1 Capacity-building methods

Action learning was used in three of the interventions: an age diversity programme (Fuertes et al., 2013), Attracting Diversity (RSE, 2018) and the Enterprise and Diversity Alliance (EDA) (Trehan et al., 2012). Action learning is a widely used intervention for leadership and organisation development, and has demonstrated tangible outcomes in many organisational settings (Cho and Egan, 2009). For the EDA, action learning provided a way for each participant to explore how they could improve engagement with business owners from diverse backgrounds. This resulted in a variety of proposed actions, which included one-to-one meetings, dedicated workshops with entrepreneurs, meetings with intermediaries and sponsored business events.

Attracting Diversity hosted action learning events with 23 Scottish universities and colleges, which supported participants to develop tailored approaches to widening access. Outcomes reported by the Royal Society of Edinburgh (2018) included the development of women-only courses in areas of severe occupational segregation (for example, Women into Engineering and Women in Construction developed by the City of Glasgow College). These courses have enjoyed a notable increase in female enrolments and work placements.

Summary

* employment assessment carried out by
* aspects to be used in the UK and IR literature.
* Safety testing was used to an effective,
* aspects to finding operational capacity.
* Safety testing was used to ensure the course of
* Safety testing was used to ensure the course of

### Why were these interventions more or less effective?

Above we have reviewed the evidence for EDI interventions that have been more, or less, effective across a number of sources, contexts and (where possible) protected characteristics. While these examples address the 'yes' or 'no' component of the current research question, they lack insight into the 'why?' element. This final section discusses reasons for the effectiveness and ineffectiveness of interventions, as noted in the sources, and any reasons suggested for why this might be the case. In this section, we look across the interventions reviewed to examine types of outcome reported and any reasons cited for successes and/or failures.

#### 5.7.1 Outcomes reported

The evaluation framework extracted information regarding interventions' intended areas of impact (recruitment, career development, culture and wellbeing etc.), intervention type and methodological approach in a quantitative manner. However, the variety of outcomes considered within the current database limited our ability to quantify this information in a meaningful way. In other words, there were too many different types of outcome explored across the 82 interventions analysed in this report to create categories that would be large enough for quantitative analysis.

As such, we extracted qualitative information regarding the outcome explored within each intervention and used a thematic approach to identify the main types of outcome being explored.

The most commonly reported outcomes related to engagement or uptake of an intervention. Outcomes that related to learnings from interventions were also commonly reported. These short-term outcomes describe the early effects of an intervention. They suggest an effect following an intervention's immediate delivery but do not show long-term change. Some interventions presented outcomes that demonstrated an effect on an individual's experiences, achievements or progression, such as their career development (for example, success in applying for jobs or promotions), job satisfaction or retention (of specific target groups, for example). These longer-term outcomes are more challenging to measure, as discussed in the next chapter.

#### 5.7.2 In what ways were interventions less effective?

No interventions reported a total failure. However, some highlighted areas that had been less effective, such as:

* little or no measurable impact on people's behaviour
* little or no impact on an organisation's policies (or intentions to change policies)
* failure to reach certain audiences, such as postgraduate students
* failure to change overall gender balance
* the intervention was not well-received by staff.

#### 5.7.3 Why did they work?

The evaluation framework extracted information from sources on reasons stated for success. This data, presented from the point of view of source author(s), elucidates potential reasons for effectiveness. Although reasons cited were specific to individual interventions, some common reasons emerged:

* **collaboration:** between subject experts, different parts of an organisation and external organisations or funders during the design and/or delivery of an intervention
* **leadership:** senior management support for an intervention
* **strategic alignment and drivers:** alignment with organisational or sector strategy and/or where strategy acts as a driver for an intervention
* **finance and resource:** the provision of funds and adequate staff resources to deliver an intervention
* **community:** interventions that created positive relationships and networks for the individuals involved
* **communication:** interventions that raised awareness of EDI within an organisation
* **learning and confidence:** interventions that increased participants' knowledge, skills and confidence
* **evidence:** use of evidence to justify the need for an intervention
* **project management and accountability:** the existence of well-defined goals, expectations and roles
* **embedding:** where an intervention became part of core business rather than a bolt-on.

#### 5.7.4 What did not work?

The review also extracted information from sources on reasons why interventions were perceived as less successful than anticipated. Common reasons included:

* **resources and recognition:** provision of insufficient resources to deliver an intervention, which might include the burden of work falling on one or two people or lack of recognition for work
* **ongoing support:** a lack of ongoing support for EDI beyond the life of an intervention
* **timescales:** short timescales limiting the potential impact of interventions
* **racial diversity of participants:** a dominance of white participants in EDI interventions
* **inconsistencies:** inconsistent application of new processes or policies
* **data:** limitations such as small sample sizes and missing data (for example, failure to capture data on participants' identity characteristics)
* **reluctance:** a reluctance within some organisations to adopt a more radical approach to tackling inequalities, such as measures to deliver positive action.

### Chapter summary

This chapter has presented results from a range of intervention types, including: training; strategy, policy and process; career development interventions; recognition schemes; and employer engagement and outreach.

#### 5.8.1 Effectiveness

The most frequently reported type of effectiveness related to levels of participant engagement, uptake, awareness raising or organisational capacity-building. A small number of interventions noted impacts related to staff or student retention or progression.

No interventions reported total failure. However, some highlighted areas where they had been less effective, such as changes in people's behaviour or an organisation's policies.

A lack of long-term evaluation was an issue across most interventions.

#### 5.8.2 Protected characteristics

Across all intervention types, effective interventions primarily focused on gender equality, with women as the typical target group. EDI in general was the next most common focus, followed by race equality, age and disability. Other protected characteristics were markedly absent from interventions that reported results (for example, socio-economic status was noted in just one intervention).

#### 5.8.3 Areas of research and innovation landscape

Interventions that presented results and adopted a specific focus on innovation were not present among those reviewed. Two interventions were identified but did not report any outcomes. This absence suggests a lack of evaluated and/or published EDI interventions focused on innovation in a UK context.

There was also a dominance of interventions from the HE sector. While Advance HE's role may have influenced the interventions identified, as noted in section 2.2, the review's methodology was designed to counteract this potential bias. Taking into account the design of the methodology and input from Advisory Group members who work outside of HE, our findings suggest that a larger proportion of evaluations of EDI interventions have been conducted in HE than other R&I sectors.

\begin{table}
\begin{tabular}{|p{113.8pt}|p{113.8pt}|p{113.8pt}|p{113.8pt}|p{113.8pt}|} \hline \multicolumn{1}{|c|}{Resumerations from this section} & \multicolumn{1}{c|}{Policy} & \multicolumn{1}{c|}{Fundes} & \multicolumn{1}{c|}{Employer} & \multicolumn{1}{c|}{Research} \\ \hline Enhance evaluation approaches of EDI training to consider longer-term impacts and the effects of training on participants behaviours and decision making. & & & & \\ \hline Interventions reviewed had a strong focus on women and/or parents. Further work is required to assess the efficacy of interventions, and different types of intervention, for people with other identity characteristics where there is evidence of need (for example, underrepresentation or unequal outcomes). & & & \\ \hline Support or conduct evaluations of EDI-focused mentoring programmes to determine their efficacy, and consider developing programmes for groups beyond women. & & & \\ \hline Returships have demonstrated promising results. R&R1 employers may wish to consider if such an intervention would benefit their organisation, particularly for women and/or individuals returning from extended career breaks. & & & \\ \hline When designing EDI interventions, consider the facilitative factors presented in this report, such as collaboration (for example, with subject experts, with different parts of the organisation or with external organisations), senior management backing, suitable funds and staff resource, project management and accountability. & & & \\ \hline Employer engagement interventions appear to work well in STEM, particularly in relation to gender. Consider whether such programmes could work in non-STEM industries and for other identity characteristics or EDI more broadly. & & & \\ \hline Develop and expand interventions related to EDI in innovation. & & & \\ \hline \end{tabular}
\end{table}
Table 5.2. Summary of recommendations from what works?

## Chapter 6 Measuring success

How is the effectiveness of EDI interventions measured? Are there methods that are particularly useful for the research and innovation landscape?

### Overview

This chapter considers the evaluation of interventions and how we can have confidence in the impact (or lack of impact) they report. In order to explore these themes, this chapter presents findings from the following evaluation framework questions:

* were outcomes measured and evaluated and are results reported?
* what type of evaluation data was captured (for example, quantitative, qualitative, or both)?
* what types of methodology were used to evaluate the different types of intervention?
* where possible, can the Maryland Scientific Method Scale be used to describe the rigour of the evaluation, or are there other ways to assess rigour that are more appropriate for EDI research in the R&I landscape?

We analysed question responses, alongside other data from the framework, to present an account of: methodological approaches used to evaluate EDI interventions; the robustness of work taking place in the R&I sector; hierarchies of evidence; and critical reflections (from the sources) on evaluation challenges.

### Methodological hierarchies

To address how the effectiveness of EDI interventions is measured, this section presents both an overview of the different evaluation methods present in the current sample and specific case studies that showcase how these methods can be applied effectively in the R&I landscape.

Traditional frameworks, such as the Maryland Scientific Method Scale, adopt a hierarchal approach that places simpler methods which employ fewer statistical or experimental controls (such as a cross-sectional comparison of a control and an experimental group) on lower levels than those that exert a higher degree of control using randomisation techniques (in other words, a randomised control trial or RCT).

An adapted version of the Maryland Scientific Method Scale (to the EDI context) was used in the current review to rate the scientific rigour of each evaluation and contribute to our overall rating of confidence in interventions' effectiveness (see table 3.7 for a summary).

Table 3.7 shows that almost two thirds of interventions could not be classified on this scale, either because there was insufficient information provided in the publication to clearly categorise its evaluation method, or because the intervention was assessed using non-experimental approaches (described in section 6.3.3). Of those interventions that were classifiable, only five (6.1%) exerted some form of experimental control (in other words, were labelled as Level 3 and above), meaning that half of the Maryland Scientific Method Scale was not applicable or useful in evaluating the rigour of the current sample.

This is a major limitation to the use of this hierarchy in the EDI context, given the challenges with small sample sizes noted in earlier chapters.

Among interventions where the Maryland Scientific Method Scale did apply, three were classified as Level 5 interventions (RCTs). These were identified from the search of grey literature and were designed and implemented by BIT in partnership with the Government Equalities Office (GEO) (two interventions) and Avon and Somerset Constabulary (one intervention). No Level 5 interventions were located among the 12 academic interventions reviewed. This review therefore shows that, within the current sample of UK sources, BIT and its partner organisations are leading in terms of the use of RCTs to evaluate EDI interventions.

Further to the difficulty of categorisation, there is also the question of the equality impact of any such implied hierarchy of categorisation. A hierarchal valuing of different evidence sources has been conceptually critiqued for its failure to account for the contexts of how knowledge is produced and disseminated (see, for example, Nair, 2012). For example, certain academic disciplines are more likely (or better resourced) to conduct large-scale experimental designs, whereas others focus on action learning.

Moreover, certain types of data source may be privileged, such as quantitative data on staff uptake of a policy rather than qualitative data from interviews about staff experiences of a policy.

#### 6.2.1 Alternative forms of evaluation and synthesis

To help address problems associated with the Maryland Scientific Method Scale, the evaluation framework also gathered information on how sources assessed the robustness of their work.

Very few sources described evaluation approaches that considered EDI interventions using multiple or mixed methods. Those that evaluated an intervention using multiple sources of evidence generally followed the same approach:

* within-group or between-group design (for example, statistical analysis of EDI staff data for award holders and non-award holders or a survey of training participants before and after the intervention)
* followed by supplementary non-experimental methods (for example, interviews, case studies) to present a convincing case that changes were causal rather than correlative.

This approach has many strengths. For example, Loughborough University's review of the Aurora women-only leadership development programme **Onwards and Upwards? Tracking Women's Work Experiences in Higher Education** (2.4%) undertook a longitudinal study of 2,240 Aurora and non-Aurora participants that considered career trajectories, aspirations and work experiences. Although this method alone could not prove a causal link between the intervention and outcomes, it was further supplemented by one-to-one interviews with participants and non-participants. This triangulation of evidence helped strengthen results from the longitudinal study and, as far as possible, presents a convincing case that the intervention had an effect on outcomes.

### Outcome measurement and reporting

One of the major challenges in investigating the impact or effectiveness of an EDI intervention is determining how to measure its intended outcomes. Should impact be reflected in quantitative statistics such as Likert scale ratings on a survey, or promotion rates over time? Or should the outcomes of an EDI intervention take a closer look at the human experience and capture qualitative data from interviews, focus groups or journal entries?

There are a number of factors to consider when answering these questions, and which outcomes are measured, and how, will depend on:

* the nature of the intervention (for instance, is it a change in policy or the introduction of a new training or mentorship programme?)
* the timeframe of the research (for instance would annual data capture the effect or would the policy changes take more than a year or two to come to fruition?).

Using the information yielded by the evaluation framework, this review considers how outcomes were measured across different contexts (for instance, academic, grey or Call for Evidence sources), the various types of intervention and whether there are gaps in how data is measured and presented as evidence.

All interventions captured data in some form, although the framework did not specify whether data was captured to evaluate the intervention or for another purpose (such as communications and marketing). Thirty-five interventions (42.7%) captured both quantitative and qualitative data, 24 interventions (29.3%) captured quantitative only and two interventions (2.4%) captured qualitative only. In 21 interventions (25.6%), it was unclear what type of data was captured. Further work is therefore required to improve how those writing about EDI interventions discuss and present data.

The type of data collected varied between academic sources, grey literature and responses to the Call for Evidence. For example, eight interventions (42.1%) to the Call for Evidence reported quantitative data only. This was notably higher than among interventions from grey literature (14 interventions, or 27.5%) and academic sources (two interventions, or 16.7%). This suggests that, when invited to share evaluation information in the Call for Evidence, many organisations assumed an expectation to return quantitative data only, rather than qualitative data only or a mix of both types of data.

In 38 interventions (46.3%), outcomes were measured/evaluated and results were reported. The evaluation framework also found that, in 11 interventions (13.4%), outcomes were measured/evaluated but not reported. This was particularly the case with Call for Evidence responses: six interventions (31.6% of responses) stated that outcomes had been measured/evaluated but failed to present results to support this claim. Addressing this missing step should present a quick win as this suggests that the problem relates to the presentation of evaluation data from EDI interventions, rather than the collection and analysis of this data.

Of greater concern is that, within the current sample, 33 interventions (40.2%) noted that outcomes were not measured/evaluated. As this finding makes clear, a gap exists between the implementation of an intervention and the measurement and reporting of outcomes. For example, _Black and Minority Ethnic Leaders in the Health Sector_ (2013) presented information about the Mary Seacole Awards, an awards scheme established in 1994 to support and develop the leadership skills of BME nurs midwives and health visitors in the NHS. The source stated that mentoring and development opportunities arising from these awards had a positive effect on promotion opportunities and progress for BME staff. However, the source failed to report any concrete outcomes from this intervention or information on how outcomes were measured and monitored. Without this vital information, this source did not convincingly demonstrate that changes suggested were a positive outcome of the Mary Seacole Awards.

#### 6.3.1 Evaluation methods

This subsection explores the types of evaluation methods present in the current sample by looking at how they have been applied across different intervention types and EDI areas, as well as focusing-in on the methods themselves, highlighting sources that have applied specific approaches in an appropriate and informative manner.

To develop a clearer idea about types of evaluation method and the contexts within which they were used, the framework presented a list of nine possible methods (and two additional categories for those that did not adopt or describe a method). Originally, these methods were presented in non-mutually exclusive categories so that we could see the overall frequencies of each methodological approach (see table 6.1) as well as which studies adopted multiple methods.

\begin{table}
\begin{tabular}{l r} \hline \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \multicolumn{1}{c}{} & \\ \hline \hline \hline \end{tabular}
\end{table}
Table 6.1: Type of introductory used for evaluate the intervention.

However, in order to gain insight into which methods were being used in different contexts, we created mutually exclusive categories for each method (presented in table 3.6 in section 3.5.6) and compared them across (i) individual types of intervention and (ii) the EDI areas listed in the evaluation framework (see table 6.2).

A mixed-method approach to evaluation was most frequent in interventions that considered multiple intervention types (six) and/or focused on EDI areas related to an individual's career (such as recruitment, promotion, leave policies) (10).

It is worth noting that some evaluation methods were used more frequently than others. For example, only one intervention used a time series analysis and two interventions used a within-groups/longitudinal method. Among the more frequently used methods, their use was spread across a variety of intervention types. For instance, between-groups/cross-sectional analyses were used across all intervention types, with the exception of positive action interventions, suggesting that this approach is particularly adaptable to evaluating a variety of intervention types. However, the relatively low application of other methods within the current sample makes it difficult to draw any strong conclusions between the use of evaluation methods and particular intervention types or EDI areas.

#### 6.3.2 Experimental manipulations and randomised designs

Experimental evaluation methods include those in which the researcher deliberately changes something (known as the independent variable) to observe the effect on something else (known as the dependent variable). This might include methods that compare experiences within one group at two or more time points (a within-group, time series or longitudinal study) or between a treatment group (who were exposed to the intervention) and a control group (who were not exposed to the intervention). When the distribution of participants across both groups is randomised, this is known as a RCT.

A small number of sources used experimental evaluation methods: 10 interventions reported use of a between-groups/cross-sectional method and two interventions reported use of a within-groups/longitudinal method. Among interventions that used experimental methods, two common challenges emerged:

* **small sample sizes:** overall numbers for EDI interventions and sub-samples (for example, analysis by specific identity characteristics)
* **establishing explicit links between the intervention and observed changes**: disentangling identity characteristics from wider EDI issues to establish the impact of an intervention; an experimental method alongside the triangulation of other evidence can help to improve the interpretation of results.

Addressing these challenges in turn, three interventions noted difficulties encountered due to the small size of samples. _Evaluating the 'Achieving Race Equality in Higher Education' Programme_ (2018) highlighted the difficulty to statistically control other characteristics or background factors, which limited what could be said about the effect of an intervention on a target group. Furthermore, as discussed in _Understanding mental health in the research environment: a rapid evidence assessment_ (2017), a small sample size also impeded the ability of researchers to undertake evaluations that considered specific elements of an intervention or went beyond a high-level account of impacts.

While experimental designs improve researchers' ability to tie an intervention to its desired effect, these approaches cannot always disentangle identity characteristics from wider EDI issues to clearly establish the impact of an intervention. As mentioned above, an experimental method alongside the triangulation of other evidence can help to improve the interpretation of results. _Evaluation of Project Juno: final report_ (2013) presented information on the Institute of Physics' awards scheme to recognise and reward university physics departments that address the subject's underrepresentation of women. The evaluation used multiple methods (a survey and focus groups) to assess the experiences of staff across 15 physics departments in the UK and Ireland. Both Juno participants and non-Juno participants were included in the study. Although the study deployed a mixed-methods approach, the design of its methodology did not make it possible for researchers to prove or disprove a causal link between Juno and the outcomes it measured. This gap was not unique to this source but it raises a bigger point about the selection of evaluation methods that can, where possible, prove or disprove impact. As discussed later in this chapter, this is not always possible and, as was the case with the evaluation of Project Juno, evaluation might instead choose to focus on the triangulation of evidence.

The use of experimental methods to evaluate EDI interventions presents many challenges. Sources reviewed did not highlight any particular strengths related to their application to assess EDI work in the R&I context. However, as the number of sources that used experimental methods was low, it should not be assumed that other methods were preferable but instead may reflect a lack of resources or support in conducting this type of research within the field of EDI.

### Strengths and limitations

In sum, there are three main challenges in adopting an experimental design to investigate the effectiveness of an EDI intervention:

* difficulty of randomly assigning participants to different conditions
* difficulty of applying this method to EDI interventions that are less open to manipulation, such as those related to organisational reviews or programmes open to all staff and/or students
* it may not reflect how the intervention will present itself in the real-world context, where other psychological, social and environmental factors may improve or hinder its effectiveness.

However, with regard to the last challenge, a number of experimental studies measure other factors (such as motivation to attend a diversity training programme, or socio-demographic factors such as current age and contract level when looking at promotion policies) that can be statistically taken into account when calculating the impact of the intervention on the outcome variable. Moreover, when applied in an appropriate manner, an experimental design provides clearer insight into the relation between an intervention and its outcomes compared with other correlation-based approaches that do not exert the same degree of control over conditions.

#### 6.3.3 Non-experimental methods and valuable alternatives

Non-experimental methods include a variety of methodological approaches, some quantitative in nature (such as surveys or questionnaires administered at a single time point or over time as in a longitudinal design, or a time series analysis) while others collect qualitative information (for example, interviews, focus groups, or document analysis). The important distinction between these and the experimental methods described above is that non-experimental methods are missing the manipulation imposed by the researcher. As such, these methods are more susceptible to 'noise' in the data (such as differences in participants' background, experiences and motivations) that limits the interpretation of cause and effect in evaluating an intervention.

Among the EDI interventions reviewed, common non-experimental methods included questionnaires, one-to-one interviews and focus groups.

Interventions most often utilised a range of experimental and non-experimental methods. However, data from the framework shows a relatively high count of interventions that undertook qualitative analysis of interviews (11 interventions), with other methods including case study/studies (eight interventions), qualitative analysis of focus groups (four interventions) and ethnography/observation (one intervention). Several challenges were noted in relation to the design, implementation and analysis of these evaluation methods, including:

* **isolated studies**: no comparison over time or between control and treatment groups.
* **small samples**: low response rate to surveys or recruitment of focus group participants etc.

Addressing these challenges in turn, several interventions were very context-specific (such as. an intervention for a small group of participants within one university), which made it difficult for evaluations to report on the generalisability of this intervention across other disciplines or sectors. Furthermore, as noted in _Understanding mental health in the research environment: a rapid evidence assessment_ (2017), many interventions described were conducted for a fixed, short period of time, which reduced the possibility of evaluating medium- or long-term impacts.

Similar to the challenges associated with experimental designs, the challenge of small sample sizes was also noted among interventions that used non-experimental methods, suggesting that this is common to EDI research in general rather than limited to a specific method of evaluation. This was most frequently noted in relation to low survey response rates or difficulties encountered during the recruitment of participants for focus groups or one-to-one interviews. To address this challenge, some interventions chose to recruit participants from large urban areas (for example, _Extending working lives: age management in SMEs_ (2013)) or focus on the identity characteristic of gender/sex.

The use of non-experimental methods to evaluate EDI interventions brings many challenges. However, as will be discussed, their use to collect diverse types of evidence can empower researchers to demonstrate the effect of interventions through the triangulation of evidence.

### Chapter summary

Meta-analyses, an assessment of multiple evaluation methodologies, are not discussed as none of the sources in the review applied this method. According to traditional meta-analytic practice, meta-analytic techniques should not be applied to samples including fewer than seven independent effect sizes (Rosenthal, 1984). As such, not only were we unable to undertake any form of meta-analysis on the interventions and effect sizes present within the current sample, but this limitation also mirrored one of the main challenges in investigating EDI within the RBI landscape: too few evaluations adopted methodological approaches that went beyond the use of high-level data (such as staff recruitment and promotion rates, national labour force statistics etc.) and took a more rigorous approach to defining and measuring the outcomes of EDI interventions (see additional discussion by Evans and Glover, 2012).

Having considered the experimental and non-experimental methods used to evaluate EDI interventions in the current sample, can we reach any conclusions as to the types used, challenges faced or confidence in the impact (or lack of impact) they report?

Key findings from this chapter include:

* **quantitative data:** 42.1% of responses to the Call for Evidence included quantitative data only; this suggests an assumption, within organisations invited to share information on EDI evaluations, that quantitative data is preferred above qualitative data only or a mix of both data types
* **reporting outcome measurement/evaluation data:** six interventions stated that data on outcomes had been collected; however, for unknown reasons, they did not report this data and further work is required to establish why organisations collect evaluation data but do not share their findings (in other words, is the problem with data storage, the sharing of data etc.?)
* **small sample sizes:** for both experimental and non-experimental methods, small samples had an effect on the focus of work (for example, geographical location, protected characteristic etc.) and the ability to conduct analysis of sub-samples
* **presenting a convincing case:** as the Maryland Scientific Method Scale did not apply to almost two in three interventions reviewed, an alternative approach to the assessment of evidence in EDI interventions is required; several sources triangulated evidence from a range of methods in an attempt to demonstrate the effect of interventions on outcomes and this approach was also used in this review to assess the effectiveness or ineffectiveness of interventions (see chapter 5).

\begin{table}
\begin{tabular}{|l|c|c|c|c|c|} \hline \multicolumn{1}{|c|}{Resumer-fitting from this section} & \multicolumn{1}{|c|}{Policy} & \multicolumn{1}{|c|}{Finders} & \multicolumn{1}{|c|}{Employer} & \multicolumn{1}{|c|}{Research} \\ \hline \multicolumn{1}{|c|}{} & \multicolumn{1}{|c|}{Index} & \multicolumn{1}{|c|}{} & \multicolumn{1}{|c|}{} & \multicolumn{1}{|c|}{} & \multicolumn{1}{|c|}{} & \multicolumn{1}{|c|}{} \\ \hline Develop skills on how to discuss and present & & & & & & \\ data among those asked to write about EDI & & & & & & \\ interventions. & & & & & & \\ \hline Measure outcomes in multiple ways to gain a full & & & & & & \\ picture of an interventions impact. & & & & & \\ \hline Highlight the value of qualitative data as a method & & & & & \\ to evaluate EDI interventions. & & & & & \\ \hline Design evaluations so that, as far as possible, & & & & & \\ they use experimental methods (for example, & & & & & \\ rather than one survey at a single time point for & & & & & \\ participants, run one survey with participants and & & & & & \\ one survey with non-participants). & & & & & \\ \hline \end{tabular}
\end{table}
Table 6.3. Summary of recommendations from Measuring success.

## Chapter 7 Enhancing data

and disclosureHow is the effectiveness of EDI interventions measured? Are there methods that are particularly useful for the research and innovation landscape?

### Overview

This chapter focuses on the capture and disclosure of EDI data and how it is used to understand barriers and challenges, draw comparisons across sectors and organisations, and measure change. Sources discussed in this chapter come from the four data collection streams, with a particularly high prevalence of grey literature. Interestingly, no academic sources included in this review explicitly discussed data and disclosure.

This chapter addresses the following themes:

**categorisation:** equality monitoring questions and response options

**drivers:** reasons why organisations collect EDI data

**encouraging disclosure:** the effect of environmental, technological and behavioural factors on disclosure, and what organisations can do to increase disclosure

**limitations and future work:** challenges, blind spots and areas of future work.

#### 7.1.1 What is EDI data?

EDI data provides an evidence base to take action to address EDI challenges. Data comes in two forms: quantitative (related to quantities, such as statistics) or qualitative (related to qualities, such as a focus group transcript where participants discussed inclusion). To reflect the use of EDI data in interventions discussed in this review (see section 6.3), this chapter focuses on quantitative EDI data and its use to describe challenges and provide an evidence base for action.

This chapter uses the term 'equality monitoring' to describe the capture of data about the diversity of a population (for example, postgraduate students, employees, fellows, grant recipients), usually via an online or paper form. When data is monitored over a period of time (in other words, using multiple capture points), it is possible to track change within a population.

#### 7.1.2 What is disclosure?

This chapter also considers ways to enhance disclosure, which involves the environmental, technological and behavioural factors within an organisation that might encourage or discourage someone from sharing information about their identity characteristics. There is an overlap between factors that encourage disclosure and the development of an inclusive organisational culture.

### Categorisation

Defining the identity groups to which people can belong is a fundamental element of the collection of EDI data. Within public sector organisations with legal requirements to report EDI data, the collection of this data generally covers the nine protected characteristics outlined in the Equality Act. For subcategories, such as ethnic group or impairment type, these most often align with response options provided in UK censuses. Within private sector organisations, which may have a different or no legal requirement to publish EDI data across the protected characteristics, alignment of EDI data collection with the protected characteristics makes it possible to benchmark progress against other comparable organisations.

Different approaches to equality monitoring questions are found across the UK's four nations (in particular, questions about religion and belief, and race and ethnicity). This reflects historical and cultural factors, different equality legislation in Northern Ireland and variance across the Equality Act's public sector equality duties in England, Scotland and Wales.

Among sources reviewed, several discussed data categorisation within the HE sector. HEIs have a legal obligation to return data to the Higher Education Statistics Agency (HESA) on the protected characteristics of staff and students within their institution. Statistical reports (Advance HE, 2018) have presented a breakdown of staff and student data by age, disability, ethnicity and gender, and the intersections of these categories. As of 2018, the reports also include data on sexual orientation, religion and belief,and gender reassignment. For R&I organisations outside of HE, these reports present a breakdown of characteristics by subject area (computer science, physical sciences etc.) for undergraduate and postgraduate students, which provides an insight into future pipeline issues for employers.

Although requirements differ across UK nations and protected characteristics, two themes related to categorisation emerged from our sources that informed EDI data and disclosure in RBI sectors.

#### 7.2.1 Sex and gender

Recent debate has emerged over equality monitoring questions using the terms 'gender' and'sex'. Some feel that asking questions about gender is more inclusive than asking questions about sex and highlight how trans people can be outed if they are asked about their sex, followed by a question about their gender identity. However, for many organisations, there is a need to collect information on sex due to the requirements of equality legislation and for data collection agencies to publish and provide this data.

Within the HE sector, HESA requires institutions to collect data on sex using the categories'male', 'female' and 'other'. **Supplementary guidance** notes that the category 'other' can include "people who associate with the terms intersex, androgyme, intergender, ambigender, gender fluid, polygender and genderqueer". A movement away from binary understandings of sex and gender is also reflected in whether respondents are invited to self-identity their sex or gender or respond in a way that aligns with formal documentation (for example, 'biological" or 'legal' sex, as documented on birth certificates). These discussions go beyond HE and are important for all employers who wish to promote an inclusive approach to the collection of staff equality monitoring data.

#### 7.2.2 Monitoring questions

A common challenge that emerged was discrepancies in monitoring questions and response options between different organisations, which can make it difficult to collate data from various organisations to gain a picture of how a sector is performing on EDI. **Review of HR systems in the Scottish college sector**(ECU, 2017) found inconsistencies in how questions were asked and the response options provided within Scotland's college sector.

For example, questions about ethnicity generally followed the question wording and response options in the 2011 census. There was, however, far greater variability in questions about disability, gender identity and reassignment, and religion or belief. These differences hampered attempts to compare and contrast data across Scotland's college sector.

### 7.3 Drivers

Sources presented multiple reasons why organisations capture EDI data. These included:

* **accreditation schemes or awards**: such as Athena SWAN (ECU, 2014), Project Juno (Institute of Physics, 2013) and the Tech Talent Charter (2019)
* **legislative and sector reporting requirements**: such as gender pay gap reporting (excludes Northern Ireland) (Advance HE, 2018) and the Royal Academy of Engineering's Diversity and Inclusion Progression Framework (2017)
* **reach and impact of an organisation's work**: for example, EDI data as an evidence base to ensure an organisation's potential is maximised (Bridge Group, 2017).

#### 7.3.1 Accreditation schemes or awards

An organisation's decision to apply for an EDI accreditation or award will likely involve rigorous internal analysis of EDI data. For some organisations, this initiative will open further discussions about HR data collection systems, missing data, and aggregated and disaggregated data. Charters also present the opportunity for EDI data collection and comparisons across organisations and sectors, which can drive further improvement. As noted in the recent _Tech Talent Charter benchmarking report_ (2019), this charter has brought together EDI data from across its signatories, which represent a huge range of types and sizes of organisation.

Although accreditation and awards can serve as a driver to enhance approaches to data collection, they can also create problems for an organisation's wider EDI work. As noted in Loughborough University's _Evaluating the effectiveness and impact of the Athena SWAN Charter: executive summary_ (ECU, 2014), the collection and analysis of data for an Athena SWAN application can require a huge amount of time and resources. The source highlighted that this brought particular risks for female staff, who might take on more than their fair share of work and were therefore disproportionately burdened by the task of data collection, analysis and presentation.

#### 7.3.2 Legislative and sector reporting requirements

Two sources presented legislative or sectoral EDI data reporting. The Royal Academy of Engineering's Diversity and Inclusion Progression Framework benchmarking exercise for professional engineering institutions and scientific bodies provided a baseline against which engineering organisations could measure their progress. Participation required organisations to self-assess their progress on diversity and inclusion (D&I) in eight areas of work across four levels of good practice, which involved returning EDI monitoring data on their staff and memberships to the Academy. The benchmarking report (2017) presented sector progress and highlighted some data gaps (such as data related to ethnicity).

Actions to mitigate the gender pay gap in English higher education (Advance HE, 2018) reported on HEIs' gender pay gap reporting in England. In 2017, all public, private and third sector organisations with over 250 employees became legally obliged to submit figures that compared men and women's average pay and were encouraged to provide a narrative that explained the underpinning factors behind any gender pay gap in their organisation, along with any measures in place to help mitigate disparities. The report shared a wide range of narrative responses and actions taken by HEIs, which demonstrated the impact of this legal driver on EDI data collection and reporting.

#### 7.3.3 Reach and impact of an organisation's work

Several sources emphasised the use of EDI data to improve the reach or impact of an organisation's work. Diversity in grant awarding and recruitment at Wellcome (Bridge Group, 2017) made clear that diversity is central to the delivery of Wellcome's vision, with this underpinned and supported by a robust evidence base. The research looked at two aspects of Wellcome's EDI data: internal data collection on staff and external data on Wellcome grant applications and awards. Its findings highlighted concerns around EDI data, including the large proportion of null or unknown data about applicants' identity characteristics.

### 7.4 Encouraging disclosure

Reasons why someone may decide to share or withhold information about their identity characteristics are complex. However, at an organisational level, three key areas are likely to impact disclosure:

\begin{tabular}{l l} \hline \hline \multicolumn{1}{c}{Data collection strand} & Grey \\ Aim & Improve how staff use student EDI data. \\ Method & Royal Holloway, University of London created a 'data dashboard' \\  & that provides reports and visualisations of student progression \\  & against EDI data (protected characteristics). This can be viewed at departmental, faculty or college level and examined on a year-byyear basis to identify trends. \\ Results & Although the source does not present detailed information on outcomes, it does note that: \\  & the replacement of static EDI data PDFs with data \\  & dashboards means that staff have access to timely \\  & and better-quality data to plan actions and address \\  & equality issues \\  & data dashboards have made it easier for staff to access \\  & EDI data and identify equality challenges, investigate \\  & details and monitor student progress. \\ Why is this important? & Use of innovative technology to enhance university staffs' use of \\  & undergraduate and postgraduate student data when conducting \\  & annual reviews. \\ \hline \hline \end{tabular}

* **environmental**: development of an inclusive culture where people feel able to disclose identity characteristics without fear of negative reprisal
* **technological**: methods used to disclose information, privacy and data security
* **behaviour**: methods used to ask questions.

One source (ECU, 2017) presented several insights related to disclosure that are likely to apply across other related sectors. The research involved an audit of staff data collection and monitoring in the Scottish college sector, including an online survey (completed by 17 of Scotland's 26 colleges) and follow-up telephone interviews (with nine survey respondents). Alongside primary research, the review also analysed equality monitoring reports from seven colleges. Findings included the following:

* new staff were more willing to disclose equality monitoring data than existing staff, particularly during the recruitment process
* several colleges were in the process of changing or developing their HR systems to enable staff to self-report and manually update their equality data; it was hoped that the provision of a secure, online platform would enable staff to review and update their EDI data, when necessary (for example, a staff member may change how they identify their religion or sexual orientation).

The review of HR systems also highlighted two behavioural practices that used the circulation of parslips as a way of improving the quality of equality monitoring data held by HR:

* one college included a reminder to update equality monitoring information with staff pasylips
* one college went further and required staff to review and confirm their equality monitoring information was correct before being able to access their pasylips online.

Although outside the remit of this review, the Office for National Statistics (England and Wales), National Records Scotland and the Northern Ireland Statistics and Research Agency have conducted testing of response options and question design ahead of the 2021 censuses. Findings from this work could inform behavioural strategies to enhance the disclosure of EDI within R&I organisations.

### 7.5 Limitations and future work

Part of the challenge of writing about the limitations of EDI data and disclosure is that areas that require most urgent attention are unlikely to feature in the sources reviewed. This discussion of limitations therefore builds on points mentioned in sources, but also identifies potential blind spots in need of future work.

* **Resource allocation**: data collection and analysis are resource-intensive (ECU, 2014), so future EDI interventions must ensure this work does not fall upon staff who may already experience disadvantage (such as female early-career researchers).
* **Postgraduate research applicants**: one source (Bridge Group, 2017) highlighted the small amount of EDI data held about doctoral study applicants.
* **Socio-economic status**: the absence of discussion about data and socio-economic status. Wellcome (Bridge Group, 2017) noted how little was known about the socio-economic background of scientists and researchers. From the limited data available, it was apparent that there exists a substantial and enduring underrepresentation of people from less advantanaged backgrounds. The sources explained that this lack of knowledge has wider ramifications, as we know even less about how socio-economic status intersects with other identity characteristics (for example, ethnicity) and whether concepts such as the 'leaky pipeline' adequately explain problems experienced.
* **Develop and strengthen common approaches**: EDI data collection approaches vary considerably across different parts of the R&I landscape; generally, larger and/ or public sector organisations tend to collect employee data across the protected characteristics (Advance HE, 2018), while smaller or private sector bodies might not yet do so or may not have complete data (Royal Academy of Engineering, 2017). The use of different EDI questions or response options makes it hard to benchmark data across a sector (ECU, 2017). Related to this challenge, Wellcome (Bridge Group, 2017) recommended the establishment of a central EDI data repository on scientific funding and scientific research workforces. Working across funding bodies and UKRI, this repository would provide a platform 

[MISSING_PAGE_EMPTY:6108]

to monitor progress and make full use of new and existing data across R&I. The Royal Academy of Engineering's Diversity and Inclusion Progression Framework (2017) attempts to advance practice across different sizes and types of organisation.
* **Longitudinal data:** short, fixed-term EDI interventions make it impossible to collect data that would demonstrate medium or long-term impacts. This challenge, noted in _Improving employment opportunities for diverse engineering graduates_ (Royal Academy of Engineering, 2018), demonstrates the case for programmes, which seek to advance EDI, to run for extended periods of time to enable

\begin{table}
\begin{tabular}{|p{113.8pt}|p{113.8pt}|p{113.8pt}|p{113.8pt}|p{113.8pt}|} \hline Recommunation from Holstein section & Policy & Fundate & Employee & Research \\ \hline Ensure questions asked about sex, gender, gender reassignment and trans status and history comply with reporting requirements and, as far as possible, enable people to respond in a manner that reflects their lived experiences. & & & \\ \hline Harmonise, or facilitate harmonisation of, equality monitoring questions and response options within specific sectors to improve potential benchmarking. & & & & \\ \hline Consider the establishment of a central EDI data repository of the UKs scientific funding and scientific research workforces (Bridge Group, 2017). & & & & \\ \hline Ensure the burden of data collection, analysis and presentation to support accreditation schemes or awards does not fall upon staff who may already face disadvantage (such as female early-career researchers). & & & \\ \hline Develop and extend secure, online HR systems that enable staff to manually review and update their equality data. & & & \\ \hline Address EDI data gaps, such as information on postgraduate research applicants (formal and informal enquiries), socio-economic status and other identity characteristics. & & & \\ \hline Develop and extend data literacy skills within organisations so that the use of EDI data goes beyond reporting the diversity of a workforce and also uses data to justify interventions and evaluate their effectiveness or ineffectiveness. & & & \\ \hline \end{tabular}
\end{table}
Table 7.1: Summary of recommendations from Enhancing data and disclosure.

**Chapter 8**

**who is leading?**

[MISSING_PAGE_FAIL:57]

all returned more than one intervention to the Call for Evidence (table 8.3). It is important to note that, although these institutions responded to the Call for Evidence, they are not a representative sample of institutions that have delivered EDI interventions in the R&I context.

### Innovative approaches

We then considered organisations that were leading in relation to innovative approaches to EDI. To answer this question, we considered organisations that:

* focused on identity characteristics that, from our review of sources, received less attention (for example, age, sexual orientation or

\begin{table}
\begin{tabular}{l c} \hline \hline Organization & No of \\  & Interventional evidence \\ \hline \hline \multicolumn{2}{l}{Advance HE in total, comprised of:} & 5 \\ \hline \multicolumn{2}{l}{Advance HE (2)} & 2 \\ \hline \multicolumn{2}{l}{Equality Challenge Unit (2)} & 3 \\ \hline \multicolumn{2}{l}{Leadership Foundation (1)} & 2 \\ \hline \multicolumn{2}{l}{Behavioral Insights Team} & 3 \\ \hline \multicolumn{2}{l}{Equate Scotland} & 3 \\ \hline \multicolumn{2}{l}{Kingston University} & 2 \\ \hline \multicolumn{2}{l}{Royal Academy of Engineering} & 3 \\ \hline \multicolumn{2}{l}{Scottish Funding Council (SFC)} & 2 \\ \hline \multicolumn{2}{l}{University of Birmingham} & 2 \\ \hline \multicolumn{2}{l}{University of Sheffield} & 2 \\ \hline \hline \end{tabular}
\end{table}
Table 8.2: Organisations that delivered more than one intervention (academic and grey literature)

\begin{table}
\begin{tabular}{l c} \hline \hline Organization & No of \\  & Interventional evidence \\ \hline \hline \multicolumn{2}{l}{Glasgow Caledonian University} & 2 \\ \hline \multicolumn{2}{l}{Heriot-Watt University} & 4 \\ \hline \hline \multicolumn{2}{l}{John Innes Centre} & 6 \\ \hline \multicolumn{2}{l}{University of Glasgow} & 3 \\ \hline \multicolumn{2}{l}{University of Nottingham} & 2 \\ \hline \hline \end{tabular}
\end{table}
Table 8.3: Organisations that delivered more than one intervention (Call for Evidence)

\begin{table}
\begin{tabular}{l l l l} \hline \hline \multicolumn{1}{c}{**Identify characteristics**} & \multicolumn{1}{c}{**Agost of 161 landscape**} & \multicolumn{1}{c}{**Inactive categories**} \\ \cline{3-4} \multicolumn{1}{c}{**that receive case attention**} & \multicolumn{1}{c}{**the network classification**} & \multicolumn{1}{c}{**the network classification**} & \multicolumn{1}{c}{**the deep**} \\ \hline \hline \multirow{4}{*}{**Fully**} & **Employment Research** & **SFC and Heriot-Watt** & **Behavioural Insights Team** \\  & **Institute - age management** & **University - University** & **- (i) shared parental leave/** \\  & **in SMEs** & **Innovation Fund (UJF)** & **flexible working and (ii) police recruitment** \\  & **Government Equalities** & **University of the West of** & **BlackRock- executive** \\  & **Office (GEO) - BAME women** & **Scotland - the Changing** & **sponsorship** \\  & **councillors taskforce** & **Landscape** & **Equate Scotland - Women** \\  & **Open University - Aspire** & **WISE campaign/Amazon -** & **Making a Difference** \\  & **programme** & **Gasgow Caledonian** & **University of Glasgow-** \\  & **Engineering - Engineering** & **University - postgraduate** & **family study lounge** \\  & **Engagement programme** & **research (PGR) cultural** & **research training** \\  & **Wellcome Trust -** & **awareness training** & **guate Scotland - Women** \\  & **understanding mental health** & **University of Glasgow-** \\  & **Department Activities Office SAM-vement control-type taskforce** & **University of Glasgow-** \\  & **Data collection strand** & **Grey** \\  & **Aim** & **To develop practical ways of encouraging BAME women to become local councillors and make councils more representative of the communities they serve.** \\  & **Method** & **The BAME women councillors' taskforce was convened in May 2008 as a pilot approach. The taskforce worked with various delivery partners and took three principal forms:** \\  & **a programme of outreach events to make BAME women** & **aware of the issue of underrepresentation and open their minds to the possibility of becoming a councillor** \\  & **a programme in which they could shadow and be mentored by a councillor** \\  & **a an online first certificate course in community leadership** \\  & **Results** & **seventeen of the women who took part in the evaluation put themselves forward as candidates in the local and general elections of May 2010** \\  & **fourteen were shortlisted to stand as a councillor or MP and, of these, 10 were selected** \\  & **four were elected as local councillors.** \\  & **Why is this important?** & **This is an effective example of adopting an intersectional approach, in relation to race and gender, in the design and implementation of an intervention.** \\ \hline \hline \end{tabular}
\end{table}
Table 8.4. Organisations leading in terms of innovative approaches

#### 8.3.1 Focused on identity characteristics that received less attention

Sources highlighted in table 7.4 were the only examples to discuss particular identity characteristics or combinations of characteristics: for example, Edinburgh Napier University (age), GEO (gender and race), the Open University (disability and race), Royal Academy of Engineering (sc socio-economic status, race and gender) and the Wellcome Trust (mental health).

#### 8.3.2 Focused on aspects of the R&l landscape that received less attention

From the literature discussed in chapter 4, we can suggest that EDI has received less focus in an innovation context than in a research context. The three sources that focused on innovation were therefore highlighted in this subcategory. Two of these were interventions (Heriot-Watt University, 2019 c; University of the West of Scotland, 2019). Both considered innovation in relation to HE and were from Scotland. Although they are worthy of note because of their focus on innovation, they are at an early stage and therefore did not report any outcomes.

The postgraduate stage of the careers pipeline also received less attention.

Glasgow Caledonian University's cultural awareness training for PGR students was therefore highlighted in this category as it focused on building EDI knowledge and understanding among students at the start of their research journeys (Glasgow Caledonian University, 2019 b).

#### 8.3.3 Used inventive approaches or tools

BIT stands out in this category. As reported in chapter 6, they have used RCTs to evaluate three behaviour-change EDI interventions. The three interventions investigated whether a change in messaging can change behaviours and decision-making. Although the interventions received mixed results, the robustness of their approach to evaluation was trailblazing in terms of EDI work in the UK.

As the only example of an executive sponsorship programme included in our database, BlackRock's programme is worthy of note. Although it was not delivered by an R&l organisation, the programme has scope to transfer to this context.

Equate Scotland are also noteworthy here, as they delivered a women's retumship programme in the STEM industry in Scotland. As mentioned, retumships are not new but are rare outside corporate settings. Their project applied this methodology to a diverse range of employers to assess whether it can work in different settings and produced positive results.

The University of Glasgow's family study lounge is also noted because, as far as we can discern, this facility is the first of its kind among HEIs and research institutes.

### 8.4 Wider impact

Finally, we considered organisations that have had wider impacts on EDI in R&l at a national or regional level. This included organisations that:

* integrated EDI into research and/or innovation policies or funding frameworks to encourage and enable institutions to deliver EDI work
* provided EDI recognition schemes to drive improvement within institutions
* provided EDI engagement, training and development to upskill other organisations on EDI.

Nine organisations, which delivered 14 interventions, were considered under this criterion (table 8.5). These organisations were generally EDI organisations, sector agencies or funding bodies, which was perhaps expected from their unique positions and remits.

#### 8.4.1 Integrated EDI into research and/or innovation policies or funding frameworks

Three organisations or initiatives were included in this category. he Engineering and Physical Sciences Research Council (EPSRC), REF and the SFC. EPSRC's institutional awards identified equality and diversity as an eligible strand in the 2016-17 Institutional Sponsorships but it has since discontinued institutional sponsorship funding in this format. The impacts of the REF 2014 equality and diversity requirements were far-reaching (see below). In Scotland, the SFC's Gender Action Plan has prompted gender-focused action planning across institutions with links to funding via outcome agreements.

\begin{table}
\begin{tabular}{p{113.8pt} p{113.8pt} p{113.8pt} p{113.8pt}} \hline \hline \multicolumn{1}{c}{Integrated ED into} & \multicolumn{1}{c}{ED recognition schemes} & \multicolumn{1}{c}{ED categorization and} \\ \multicolumn{1}{c}{Transactions and/or funding} & & \multicolumn{1}{c}{capacity building for} \\ \multicolumn{1}{c}{} & & \multicolumn{1}{c}{title of computational} \\ \hline EPSRC - 2016-17 & Advance HE - Athena SWAN & Equate Scotland - \\ Institutional awards \&D & Charter & (I) Positive Action project \\ strand (discontinued) & & (II) Career/Wise \\ Research Excellence Framework 2014 - EDI measures & Institute of Physics - & University of Birmingham and partners - Enterprise \& Diversity Alliance \\ SFC - (I) Gender Action Plan and (II) UIF & Tech Talent Charter & The Royal Academy of Engineering - (I) Diversity programme, (II) Engagement \\ \hline \hline \end{tabular}
\end{table}
Table 8.5. Organisations leading in terms of wider impact

#### 8.4.2 Provided EDI recognition schemes to drive improvement within institutions

Three recognition schemes related to R&I were identified: the Athena SWAN Charter, Project Juno and the Tech Talent Charter. As discussed in chapter 5.5, they all reported an effect on the implementation of actions within institutions.

#### 8.4.3 Provided EDI engagement, training and development to upskill other organisations on EDI

Organisations that helped build the capacity of other organisations to advance EDI included HE and STEM sector agencies (Advance HE and Equate Scotland), learned societies (the Royal Academy of Engineering) and partnerships between HEIs and employers (the University of Birmingham). Most of the interventions delivered involved employer engagement or outreach. The relatively large number of interventions, and organisations working in this area, suggests that it is an area of R&I EDI work that has received relatively high attention over recent years.

Why is this important? As the mechanism that provides accountability for public investment in research, the REF has enormous potential as a lever for improving EDI in research. The 2014 REF EDAP report showed REF 2014 had a far-reaching impact on EDI.

[MISSING_PAGE_EMPTY:6118]

[MISSING_PAGE_EMPTY:6119]

## Chapter 2 Conclusions

### Gaps in the evidence base, comparing the UK and international reviews, and limitations.

The application of conventional hierarchies of evidence was inappropriate for the wide variety of sources and the nature of EDI

interventions reviewed. In particular, we found that the Maryland Scientific Methods Scale could not adequately assess a large number of interventions discussed in this research.

Research also found opportunities to improve the methodologies used to evaluate the impact of EDI interventions. Many interventions did not report their outcomes and, among those that did, there was a clear preference for quantitative data rather than qualitative data or a mix of both data types. Several interventions triangulated evidence from a range of methods to demonstrate a link between interventions and outcomes. However, a lack of long-term evaluations across the sample made it difficult to track the relationship between interventions and effects on behaviours, decision-making, retention and progression.

Data capture approaches varied across the R&I landscape, with particular challenges identified in relation to discrepancies in monitoring questions and response options, missing data on particular identity characteristics and challenges that these pose to benchmarking within or across sectors.

Some interventions acted as drivers for the collection of EDI data, such as accreditation schemes and sectoral reporting requirements, and some organisations had undertaken work to improve the quality of their sector's EDI benchmarking data.

Drawing on these findings, we identified three definitions of EDI 'leadership' that apply to organisations in the R&I landscape:

* organisations with a high output of EDI interventions
* organisations that have followed innovative approaches
* organisations with wider impact across the R&I landscape.

Multiple organisations appeared in one or more of these categories, including funding organisations, sector or discipline-specificorganisations, and individual HEIs and research institutes. We hope that these understandings of leadership will help UKRI and others to advance strategic approaches to EDI.

### Gaps in the evidence base

Across all sections of this review, gender (and primarily women) emerged as the clear focus of EDI interventions. Work on EDI in general was the next most common focus, followed by interventions related to race. All other protected characteristics and socio-economic status appeared infrequently among the sources reviewed. It is likely that gaps in monitoring and benchmarking data for some identity characteristics might contribute to these absences.

Also missing from the evidence base was work specifically focused on EDI and innovation, with just three sources on this theme. The majority of sources focused on research careers, with a particular focus on HE.

The review identified UK-wide, England-only and Scotland-only sources. One source discussed an intervention in Northern Ireland and one source discussed an intervention in Wales. However, due to the lack of information presented, these two examples were not included in the evaluation framework. While this perhaps reflects the relative sizes of different sectors, in addition to the Scottish Government's focus on EDI, future work needs to take account of differing EDI contexts across the UK.

### Comparing the UK and international reviews

When read together, the two reviews present a wide account of what works across different R&I contexts and suggests enormous scope for the transfer of effective practices. The key difference between the UK and international reviews was the type of sources identified: the UK review found a far smaller number of eligible academic sources than the international review (12 sources, compared to 82 sources) and consequently placed more emphasis on the targeted grey literature search and the Call for Evidence. This meant that the UK review included a greater proportion of unpublished and emerging practices, with less rigorous evaluations, than interventions discussed in the international review.

### Review limitations

The difference in the type of sources included in the UK and international reviews is not, in itself, a limitation. However, it does affect what we can and cannot say about the representativeness of these findings for the UK's R&I landscape as a whole. In some examples, such as self-reported reasons for an intervention's successes or failures, insights come from analysis of similarities and differences between perceptions presented in sources, rather than an assessment of our confidence in whether what was stated expressed the objective reality of the situation.

As noted in section 2.2, the review did not assess the EDI work of all organisations within the R&I landscape, nor did it assess the totality of EDI work that has taken place within organisations reviewed. Additionally, the research focused on EDI interventions rather than organisations' strategic approaches to EDI. This meant that we did not assess how organisations addressed EDI holistically. The 15-week period to conduct this review meant that we could not include organisations that had not published their EDI work or responded to our Call for Evidence. Furthermore, when sources were identified that did not include key pieces of information (numerical data on outputs, clarity on method used etc.), it was beyond the scope of this review to conduct supplementary research to plug the gaps. As our methodology could not locate what was'missing' from this review, we cannot make any value judgements about the quality of work not discussed in this review or its use to advance EDI in the R&I landscape.

## Chapter 10 Recommendations

[MISSING_PAGE_EMPTY:6125]

### Glossary

This report uses several terms that are not in common usage or can possess different meanings in different sectors. For clarity, this report uses the following definitions, except when presenting data from sources where the language or terminology of the original author(s) is used:

**BME or BAM:** This abbreviation or acronym for black and minority ethnic (or black, Asian and minority ethnic), which has limitations as it implies that BME/BAME individuals are a homogeneous group, singles out specific ethnic groups and is generally perceived to exclude white minority ethnic groups.

**Disability, disabled:** used as an overarching term to describe a range of long-term health conditions, impairments or physical or mental illness which impact on day-to-day life.

Advance HE approaches disability primarily from a social model (where societal structures disable individuals) but we are aware that this approach has its limitations and that there are different understandings (for example, some individuals who are deaf or hearing-impaired will identify as disabled, but others will not).

**EDI:** an acronym for equality, diversity and inclusion, which are concepts that possess different meanings. Some sources also refer to E&D (equality and diversity) and D&I (diversity and inclusion).

**Gender, sex:** although the two words are often used interchangeably, we understand them to have different meanings (with gender as a social rather than biological construct).

Generally, and where appropriate, Advance HE believes the word 'gender' is more inclusive than'sex' as it acknowledges a range of identities and experiences. Section 7.2 includes further discussion of these terms.

**Innovation:** this report uses the WISE campaign for gender balance in science, technology and engineering's definition: the 'creation of new products, services and ways of doing business'.

**Intervention:** used to refer to any new or changed activity (programme, training, policy, practice or way of working) with the aim of reducing differential access, experiences, progression or outcomes for those working or studying in or around the R&I sector. One source might include multiple examples of interventions.

**Intersectional, intersectionality:** developed by Professor Kimberle Crenshaw, a theory or approach that acknowledges the specific and compounding effects of oppression related to multiple identities. Originally conceived as a 'lens' to analyse the effect of structural sexism and racism on the lives of black women.

**Protected characteristics:** any of the nine identity characteristics covered under the UK's 2010 Equality Act, or Northern Irish equality legislation.

**Race:** used here primarily through its UK legal lens of referring to ethnicity, skin colour, ethnic or national origins, or nationality (including citizenship). Advance HE approaches race equality from the position that 'race' is a social construct and therefore has associated limitations and complex, changing understandings.

**Source:** any document that provides information on EDI interventions and/or challenges. This might include a paper in an academic journal, an organisation's report or a Call for Evidence response.

**STEM(M) or SET:** acronyms for science, technology, engineering, mathematics (and medicine) and science, engineering and technology. SET is most commonly used to describe aggregated HESA data on subject areas.

**UKRI:** United Kingdom Research and Innovation, which includes seven research councils, Research England and Innovate UK.

## Bibliography

* * Source identified through method but not evaluated with framework.
* # Background or contextual source neither identified through method nor evaluated.

An online bibliography that includes all sources which satisfied the review's inclusion criteria and/or provided context on past EDI challenges is available at:

[https://www.zotero.org/groups/2326259/review_of_edi_interventions/items](https://www.zotero.org/groups/2326259/review_of_edi_interventions/items)

Academy of Medical Sciences, (2017). _What do applicants want from SUSTAIN?_

Advance HE (n.d.). _Monitoring questions: recommended questions to ask about equality information._ Retrieved at [https://www.ecu.ac.uk/guidance-resources/using-data-and-evidence/monitoring-questions/](https://www.ecu.ac.uk/guidance-resources/using-data-and-evidence/monitoring-questions/)

Advance HE. (2018 a). _Actions to mitigate the gender pay gap in English higher education._

* Advance HE. (2018 b). _Equality in higher education: staff statistical report 2018._

Advance HE. (2018 c). _Identifying good practice in successful Silver and Gold Athena SWAN applications._

Advance HE, (2018 d). _Evaluating the 'Achieving Race Equality in Higher Education' programme._

Andrews, R., Ashworth, R., (2015). _Representation and inclusion in public organisations: Evidence from the UK civil service._

Ashley, L., Empson, L., (2016). _Convenient fictions and inconvenient truths: dilemmas of diversity at three leading accountancy firms._

_Critical Perspectives on Accounting, 35, pp 76-87._

[https://doi.org/10.1016/j.cpa.2015.05.002](https://doi.org/10.1016/j.cpa.2015.05.002).

Ashraf, F. (2013). _Black and minority ethnic leaders in the health sector._ _Journal of Psychological Issues in Organizational Culture, 3(S1), pp104-114._ [https://doi.org/10.1002/jproc.21068_](https://doi.org/10.1002/jproc.21068_).

Atewologun, D., Cornish, T., Tresh, F., (2018). _Unconscious bias training: an assessment of the evidence for effectiveness._ _Equality and Human Rights Commission No. Research Report 113._

Barnard, S., Arnold, J., Bosley, S., Munir, F., (2016). _Onwards and upwards? Tracking women's work experiences in higher education: summary._ The Leadership Foundation for Higher Education.

Bridge Group, (2017). _Diversity in grant awarding and recruitment at Wellcome._ The Wellcome Trust.

* Business in the Community, (2011). _Race to progress._
* Business in the Community, (2015). _Race at work 2015: executive summary._

* Business in the Community, (2018). _Seizing the momentum: mental health at work 2018 Report._

* Business in the Community, (2019). _Working with pride: issues affecting LGBT+ people in the workplace._

* Chambers, D., Preston, L., Topakas, A., de Saille, S., Salway, S., Booth, A., Wilson, J., (2017). _Review of diversity and inclusion literature and an evaluation of methodologies and metrics relating to health research._ The Wellcome Trust.

#Cho, Y., Egan, T.M., (2009). _Action learning research: a systematic review and conceptual framework._ _Human Resource Development Review, 8(4), pp 431-462._ [https://doi.org/10.1177/1534484309345656](https://doi.org/10.1177/1534484309345656).

Creative Research, (2011). _Evaluation of the black, Asian and minority ethnic women_

_councilors taskforce._

Equality and Diversity Advisory Panel, (2015). _Equality and diversity in the 2014 Research Excellence Framework: a report by the Equality and Diversity Advisory Panel (EDAP)._

* Equality Challenge Unit, (2009). _The experience of lesbian, gay, bisexual and trans staff and students in higher education._

* Equality Challenge Unit, (2011). _Experiences of black and minority ethnic staff in higher education._Equality Challenge Unit, (2012 a). _Evidence equality: increasing disclosure and take up of DSA_.

Equality Challenge Unit, (2012 b). _Mentoring: progressing women's careers in higher education_.

Equality Challenge Unit, (2014). _Evaluating the effectiveness and impact of the Athena SWAN Charter: executive summary_.

Equality Challenge Unit, (2015 a). _Governing bodies, equality and diversity in Scottish higher education institutions_.

Equality Challenge Unit, (2015 b). _Understanding adjustments: supporting staff and students who are experiencing mental health difficulties_.

*Equality Challenge Unit, (2016). _ASSET 2016: experiences of gender equality in STEMM academia and their intersections with ethnicity, sexual orientation, disability and age_.

*Equality Challenge Unit, (2017). _Review of HR systems in Scottish colleges to support improvements in workforce equality, with related recommendations_.

Equate Scotland, (2016). _Women returners Scotland: project report_.

Equate Scotland, (2018). _Positive action project: annual review, 2016-17_.

#Evans, C., Glover, J., (2012). _Diversity management change projects: in need of alternative conceptual approaches? Journal of Technology Management and Innovation_, 7(3), pp 12-21. [https://doi.org/10.4067/S0718-27242012000300002](https://doi.org/10.4067/S0718-27242012000300002)

Fuertes, V., Egdell, V., McQuaid, R., (2013). _Extending working lives: age management in SMEs_. _Employee Relations_, 35(3), pp 272-293. [https://doi.org/10.1108/01425451311320477](https://doi.org/10.1108/01425451311320477).

Glasgow Caledonian University, (2019 a). _Postgraduate research students academic writing workshops_.

Glasgow Caledonian University, (2019 b). _Induction and orientation programme for postgraduate research students_.

#Goldman Sachs, (2019). _2019 Goldman Sachs Returnship Program_. Retrieved at [https://www.goldmansachs.com/careers/professionals/returnship/](https://www.goldmansachs.com/careers/professionals/returnship/)

Government Economic Service. (n.d.). _Women in Economics_.

Guccione, K., (2018). _Aren't they all leaving anyway? What's the value of mentoring early career research staff?_ The Leadership Foundation for Higher Education.

Guthrie, S., Lichten, C., van Belle, J., Ball, S., Knack, A., Hofman, J. (2017). _Understanding mental health in the research environment: a rapid evidence assessment_. The Wellcome Trust.

Hanesworth, P., (2016). _Whose job is it anyway? Analysis of approaches to tackling gender imbalances at the subject level in Scotland's colleges and universities_. The Higher Education Academy.

Heriot-Watt University, (2019 a). _(Equality) career acceleration awards_.

Heriot-Watt University, (2019 b). _HR excellence in research_.

Heriot-Watt University, (2019 c). _REF2014 code of practice_.

Heriot-Watt University, (2019 d). _Scottish Funding Council's University Innovation Fund strand 7_.

Higher Education Funding Council for England and Equality Challenge Unit, (2017). _Sector-leading and innovative practice in advancing equality and diversity_. Higher Education Funding Council for England.

Higher Education Statistics Agency. (n.d.). _Fields required from institutions in England: sex identifier_. Retrieved at [https://www.hesa.ac.uk/collection/c16051/e/sexid](https://www.hesa.ac.uk/collection/c16051/e/sexid)

John Innes Centre, (2019 a). _Family/dependant support fund_.

John Innes Centre, (2019 b). _Institute support for the extension of fixed term contracts following parental leave_.

John Innes Centre, (2019 c). _Onsite nursery_.

John Innes Centre, (2019 d). _Parent career fund_.

John Innes Centre, (2019 e). _Parental leave policies for postdoctoral research associates and fellows on short-term contracts_.

John Innes Centre, (2019 f). _Stop the tenure clock initiative_.

King, E.B., Dawson, J.F., Kravitz, D.A., Gulick, L.M.V., (2012). _A multilevel study of the relationships between diversity training, ethnic discrimination and satisfaction in organizations. Journal of Organizational Behavior_ 33, pp 5-20.
* King et al. (2018) King, V., Roed, J., Wilson, L., (2018). _It's very different here: practice-based academic staff induction and retention. Journal of Higher Education Policy and Management_, 40(5), pp 470-484. [https://doi.org/10.1080/1360080X.2018.1496516](https://doi.org/10.1080/1360080X.2018.1496516).
* Klingler-Vidra (2019) Klingler-Vidra, R., (2019). _Global review of diversity and inclusion in business innovation._ LSE Consulting.
* Lindsay (2015) Lindsay, S., (2015). _What works for doctoral students in completing their thesis? Teaching in Higher Education_, 20(2), pp 183-196. [https://doi.org/10.1080/13562517.2014.974025](https://doi.org/10.1080/13562517.2014.974025).
* London School of Economics and Political Science. (n.d.). _Gender diversity on boards: are quotas the answer?_ Research Excellence Framework.
* Manfredi (2017) Manfredi, S., (2017). _Increasing gender diversity in senior roles in HE: who is afraid of positive action? Administrative Sciences_, 7(2), 19.
* McAllister et al. (2017) *McAllister, D., Juillerat, J., Hunter, J., (2017). _Towards a better understanding of issues affecting grant applications and success rates by female academics._
* McKinsey and Company (2016) *McKinsey and Company (2016) _The power of parity: advancing women's equality in the United Kingdom._
* what works?_ The Leadership Foundation for Higher Education.
* Wain (2012) #Nairn, S., (2012). _A critical realist approach to knowledge: implications for evidence-based practice in and beyond nursing: critical realism and nursing knowledge.__Nursing Inquiry_, 19(1), pp 6-17. [https://doi.org/10.1111/j.1440-1800.2011.00566.x](https://doi.org/10.1111/j.1440-1800.2011.00566.x)
* Noon et al. (2013) Noon, M., Healy, G., Forson, C., Oikelome, F., (2013). _The equality effects of the "hyperformization' of selection.__British Journal of Management_, 24(3), pp 333-346. [https://doi.org/10.1111/j.1467-8551.2011.00807](https://doi.org/10.1111/j.1467-8551.2011.00807).
* Raven et al. (2012) Raven, N., Storry, K., Streeton, D., (2012). _Innovative practice: learning from local practice: lessons from managing an Aim higher mentoring scheme.__Widening Participation and Lifelong Learning_, 14(1), pp 91-98. [https://doi.org/10.5456/WPLL.14.1.91](https://doi.org/10.5456/WPLL.14.1.91).
* Tech Talent Charter (2019) Tech Talent Charter, (2019). _Tech Talent Charter benchmarking report 2019._
* The Behavioural Insights Team (2015) The Behavioural Insights Team, (2015). _Promoting diversity in the police._
* The Behavioural Insights Team (2018) The Behavioural Insights Team, (2018). _Return to work: parental decision making._
* The Institute of Physics (2013) The Institute of Physics, (2013). _Evaluation of Project Juno: final report._
* The Royal Academy of Engineering (2016) The Royal Academy of Engineering, (2016). _Diversity programme report, 2011-16._
* The Royal Academy of Engineering, (2017). _Engineering and science professional body, benchmarking report 2017._
* The Royal Academy of Engineering (2018) The Royal Academy of Engineering, (2018). _Improving employment opportunities for diverse engineering graduates._
* The Royal Society of Edinburgh (2018). _Tapping all our talents 2018: a progress review of women in science, technology, engineering and mathematics in Scotland._
* Thomas (2013) Thomas, L., (2013). _What works? Facilitating an effective transition into higher education.__Widening Participation and Lifelong Learning_, 14 (1), pp4-24. [https://doi.org/10.5456/WPLL.14.S.4](https://doi.org/10.5456/WPLL.14.S.4)
* Thompson (2017) Thompson, S., (2017). _Defining and measuring 'inclusion' within an organisation_. Government Helpdesk.
* Trehan (2012) Trehan, K., (2012). _Facilitating impact: making entrepreneurship and diversity everyone's business.__ESRC end-of-award report_, RES-189-25-0194.
* University of Bristol (2018) *University of Bristol, (2018). _Getting things changed: summary of full report._
* University of Glasgow (2019 a) University of Glasgow, (2019 b). _Embedding equality and diversity in conference._
* University of Glasgow (2019 c). _Family study space._
* University of Nottingham (2019 a). _Anne McLaren scholarships._University of Nottingham, (2019 b). _Improving diversity in engineering recruitment._

University of the West of Scotland, (2019).

_The changing landscape._

University of Warwick, (2019). _Conferences equality and diversity initiative._

Vuillermoz, B., (2018). _Our blueprint for balance. Professional Manager,_ 21-21.

Waight, E., Giordano, A., (2018). _Doctoral students' access to non-academic support for mental health._ _Journal of Higher Education Policy and Management,_ 40 (4), pp 390-412. [https://doi.org/10.1080/1360080X.2018.1478613](https://doi.org/10.1080/1360080X.2018.1478613).

*Wakeling, P., Kyriacou, C., (2010). _Widening participation from undergraduate to postgraduate research degrees: a research synthesis._ The University of York.

*WISE Campaign, (2017). _Women in STEM workforce 2017._

*WISE Campaign and Amazon, (2019). _Making a difference: why women in STEM become innovators._

*Women's Business Council, (2018). _Maximising women's contribution to future economic growth._

Yelken, Y., (2018). _The Aditi Leadership Programme: developing the potential of black, Asian and minority ethnic leaders._ The Leadership Foundation for Higher Education.

[MISSING_PAGE_EMPTY:6132]

[MISSING_PAGE_EMPTY:6133]

to any area of UKRI's work. We were open to sources that documented interventions from outside the R&I sector but excluded sources that were not transferable to UKRI's work. This was particularly common with sources that discussed healthcare interventions.

### Limitations of databases

It became apparent during the review of sources that a large number related to research in the fields of healthcare and primary-level and secondary-level education were from psychology or related disciplines, and were conducted by researchers based in the US. These reflections on the potential limitations of EBSCO, OpenGrey and Scopus databases informed the other three strands of data collection.

### English-only publications

Unfortunately, given the timeframe and resources of the current review, we were only able to include publications available in English. This may have limited the number of sources from international journals, or within the grey literature search, from organisations that publish in other languages (Welsh, Chinese, Japanese etc.).

### 11.2 Call for Evidence

#### 11.2.1 Data collection

The Call for Evidence was intended as a supplementary data collection to help surface unpublished documents, encourage self-reporting (particularly of 'what doesn't work' or key learning from attempts at implementation of initiatives (practical, financial)) and provide opportunities for contextual reflection (policy drivers, scalability). It was not intended to provide'representative' data of the extent or range of work in the sector. A larger systematic call with a wider timeframe could be a useful recommendation for future work.

### How was evidence collected?

A form was developed to capture key information from institutions about interventions they had undertaken (see appendix 11.2.2). Questions were designed to be flexible so that respondents could share different types of intervention, and to be not too onerous to maximise participation and prompt institutions to return information that would help answer the project's research questions. Methods to respond included:

* completing the form online via Survey Monkey
* completing the form as a Word document and returning it by email or post, along with any supporting documents
* providing information via a telephone or Skype call with a member of the research team.

The timeline for the call was necessarily quite tight due to the need to collect the evidence in time for it to be analysed. The call was circulated on 28 January 2019 and the deadline for responses was 19 February.

[MISSING_PAGE_EMPTY:6135]

[MISSING_PAGE_EMPTY:6137]

### Data reduction

#### 11.3.1 Inclusion and exclusion criteria

The review of Athena SWAN applications also followed these eligibility criteria, with four additional requirements:

[TABLE:A1.T1][ENDT

#### 11.3.2 Final sample

After applying the inclusion criteria to the academic sources, only 10 were considered eligible for the UK review. The advisory group and research team both felt that this number was smaller than anticipated; as such, we undertook an additional search of seven journals related to EDI:

* _Journal of Higher Education Policy and Management_ (three sources)
* _Journal of Diversity in Higher Education_ (no sources)
* _Equality, Diversity and Inclusion: an International Journal_ (no sources)
* _Teaching in Higher Education_ (two sources)
* _Widening Participation and Lifelong Learning_ (three sources)
* _Higher Education Quarterly_ (no sources)
* _British Journal of Sociology of Education_ (two sources).

This additional search located a further 10 sources and, following application of the review's inclusion criteria, two sources were added to the evaluation framework. These additional sources were added to the UK sources identified via the database searches to bring the total of UK academic and grey sources gathered from this strand of data collection to 12 (as noted in the summary table below).

The Call for Evidence received responses from seven different organisations, who shared 19 discrete interventions.

The Athena SWAN sample included 63 recipients of a Silver award and seven recipients of a Gold award from the November 2017 and April 2018 rounds. The review and coding of applications identified 42 instances of 18 discrete interventions in 23 applications. The table overleaf describes the interventions located in Athena SWAN applications.

Although the review of Athena SWAN applications identified several interventions related to R&I, information presented on the evaluation methods used to assess the effectiveness of these interventions was limited. For this reason, Athena SWAN applications were excluded from the final evaluation framework.

#### Reliability

To ensure that the eligibility criteria had been applied in a similar manner across the four main 

#### 11.3.4 What is an intervention?

In order to apply inclusion and exclusion criteria, the research team had to agree on a common definition of the term 'intervention'. As noted, sources that focused on theoretical or conceptual approaches, discussions or persuasive essays were excluded.

Many sources adopted a grounded approach that explored an EDI-related phenomenon (for example, the factors that make black women more likely to join a mentorship scheme) and presented possible reasons (length of time working for the organisation, support from line manager etc.). As these examples did not evaluate a specific intervention introduced to address a challenge, they were excluded.

In other sources, EDI-related phenomena were discussed but the outcome variable was not a protected characteristic. As an example, compare these two sources:

**Excluded:** the impact of a racially diverse senior leadership team on an organisation's productivity.

**Included:** the effect of peer-to-peer mentoring on the experiences of LGBT+ young people.

In the above example, the excluded source includes an independent variable related to EDI (that is, a racially diverse senior leadership team) but the dependent variable was not more likely to join a mentorship scheme) and presented possible reasons (length of time working for the organisation, support from line manager etc.). As these examples did not evaluate a specific intervention introduced to address a challenge, they were excluded.

In other sources, EDI-related phenomena were discussed but the outcome variable was not a protected characteristic. As an example, compare these two sources:

### 11.4 Websites included in the targeted grey literature search

\begin{tabular}{l l} Academy of Social Sciences & Konfer \\ Advance HE & Leadership Foundation for HE \\ AHRC & McKinsey and Company \\ Association for Learning Technology & Microbiology Society \\ BBSRC & MRC \\ Behavioural Insights Team & National Centre for Universities and Business \\ BMA & NERC \\ British Educational Research Association & OECD \\ British Red Cross & Oxfam \\ British Science Association & Research England \\ Business in the Community & Research Excellence Framework \\ Cambridge AWiSE & Sainsbury's \\ Cancer Research UK & Sci Tech Daresbury \\ Cisco & Scottish Funding Council \\ Croda & STFC \\ Disability Rights UK & Syngenta \\ Elsevier & Tech Talent Charter \\ ENEI Awards & The Academy of Medical Sciences \\ EPSRC & The British Academy \\ Equality Challenge Unit & The Careers Research and Advisory Centre Ltd \\ Equality and Human Rights Commission & The Chartered Association of Business Schools \\ Equate Scotland & The Hartree Centre \\ ESRC & The Institute of Physics \\ European Commission - Policy Lab & The Royal Academy of Engineering \\ Francis Crook Institute & The Royal Society \\ Gateway to Research & The Royal Society of Edinburgh \\ GCHQ & The Sanger Institute (Wellcome) \\ GlaxoSmithKline & The Wellcome Trust \\ Government & UBS \\ Government Equalities Office & UK government \\ Higher Education Academy & UKRC for women \\ Higher Education Funding Council for Wales & UKRI \\ Higher Education Statistics Agency & Unilever \\ Inclusive Companies Awards & Waitrose \\ Institution of Engineering and Technology & WISE Campaign \\ Jaguar Land Rover & Zoetis \\ \end{tabular}

### Evaluation framework

#### 11.5.1 Design

The research team designed a framework that was flexible enough to evaluate different types of source but universal enough so that subsequent analysis was meaningful and able to tell a coherent story. As far as possible, discrete response options were presented to improve the quality of quantitative analysis.

The framework also had to capture information about sources and single or multiple interventions contained within each source. The framework allowed a maximum of five discrete interventions to be shared per source.

To facilitate the gathering of evaluation data, the framework was hosted on Survey Monkey. This enabled researchers across the team to simultaneously input data.

The framework required researchers to describe the intentions of interventions, the challenges they intended to address and their relevance to UKRI's work, and to assess the robustness of evaluation methods and the success or failure of interventions. The framework provided space to input data on the level of confidence that the intervention was responsible for the stated outcomes, for example using the Maryland Scientific Method Scale, as well as an intervention's reach (number of people, areas of work) and the extent of its impact (individual or institutional change). The framework's flexibility also presented opportunities to report on interventions that lacked a rigorous evidence base of impact but suggested exciting potential, as well as interventions that had limited or unexpected outcomes. All sections of the framework allowed for free text responses to ensure no meaningful information was lost during the evaluation process.

The framework underwent testing, which involved the evaluation of two sources (one academic, one grey) to help identify questions that were missing from the framework, areas of overlap and questions that did not make sense, and to aid the refinement of response options. Results from this testing led to the revision of some framework questions, including adding a question to clarify whether the source evaluated an intervention or was a review or meta-analysis, or if the source presented evidence for examples of EDI best practice without necessarily including primary data collection and/or analysis. For example, if a source described an EDI policy or initiative alongside unpublished evidence (for example, an organisation built a new university programme for recruiting women into software engineering that doubled the number of female software engineer interns), we opted to expand the evaluation framework and include the source in subsequent analysis.

#### 11.5.2 Evaluation framework

The framework presented in this section is based on the framework developed in this section. The framework is based on the framework developed in this section.

[MISSING_PAGE_EMPTY:6144]

[MISSING_PAGE_FAIL:91]

[MISSING_PAGE_EMPTY:6146]

[MISSING_PAGE_EMPTY:6147]

[MISSING_PAGE_FAIL:94]

## Acknowledgements

Advance HE wishes to thank those who have contributed to this review, including the project's Advisory Group, UKRI, UKRI's External EDI Advisory Group and respondents to the Call for Evidence, which included:

* Glasgow Caledonian University
* Heriot-Watt University
* The John Innes Centre
* The University of Glasgow
* The University of Nottingham
* The University of the West of Scotland
* The University of Warwick.

### Advisory Group members

\begin{tabular}{l l} \hline Name & Organization \\ \hline Shaun Holmes & British Council \\ \hline Louis Stupple-Harris & British Science Association \\ Rachel Handforth & Careers Research and Advisory Centre; Vitae \\ \hline Gregory Grouch & Equality \& Human Rights Commission \\ \hline Lindsey Crosswell & European Bioinformatics Institute \\ \hline Matthew Guest & GuildHE \\ Rochelle Fritch & Science Foundation Ireland \\ \hline Anna Bradshaw & British Academy \\ Karen Salt & UKRI External Advisory Group for EDI; University of Nottingham \\ \hline Rachael Gooberman-Hill & University of Bristol \\ Sheila Riddell & University of Edinburgh \\ \hline \end{tabular}

## About Advance HE

Advance HE was formed in March 2018

from a merger of the Equality Challenge Unit (ECU), the Leadership Foundation for Higher Education and the Higher Education Academy. We have over ten years' experience supporting institutions and research institutes to remove barriers to progression and success for all staff and students. We provide a central source of expertise, advice, research and leadership on equality and diversity that drives forward change and transforms organisational culture in teaching, learning, research and knowledge exchange. We are:

* A specialist body. Advance HE has substantive practical experience, expertise, and insight with relation to equality and diversity and underrepresentation pertaining to staff and students at every level and in every function of the HE and research sector.
* A focus on identifying, sharing and evidencing impactful practices: Identifying and recognising more systemic solutions to barriers to EDI is the focus of our gender and race charters work for HE institutions and research institutes. Our work in understanding, identifying and embedding impactful practice is informed by our overarching knowledge of activity in the sector and our understanding of the latest innovative interventions through discrete projects and relationships.
* Not for profit: As a registered educational charity, all funds are directly reinvested back into strengthening Advance HE's mission for the benefit of stakeholders.

Advance HE is a company limited by guarantee registered in England and Wales no. 04931031.

Registered as a charity in England and Wales no. 1101607. Registered as a charity in Scotland no. SC043946. Advance HE words and logo should not be used without our permission. VAT registered no. GB 152 1219 50.

### Contact us

+44 03300 416201

enquiries@advance-he.ac.uk

www.advance-he.ac.uk

@AdvanceHE

## About UK Research

and Innovation

Big challenges demand big thinkers- those who can unlock the answers and further our understanding of the important issues of our time. Our work encompasses everything from the physical, biological and social sciences, to innovation, engineering, medicine, the environment and the cultural impact of the arts and humanities. In all of these areas, our role is to bring together the people who can innovate and change the world for the better.

We work with the government to invest over E7 billion a year in research and innovation by partnering with academia and industry to make the impossible, possible.

Through the UK's nine leading academic and industrial funding councils, we create knowledge with impact.

Promoting equality, diversity and inclusion is at the heart of UK Research and Innovation's (IJKI!) vision.

We believe that equality, diversity and inclusion - of people and ideas - is integral to excellence in research and innovation, letting us access the best talent and nurture great ideas. We therefore embed equality, diversity and inclusion at all levels and in all that we do, both as an organisation and as a funder.

UKRI works to ensure that every employee is treated with dignity and respect. We will not accept bullying and harassment in any form and we are developing an action and engagement plan to ensure the UK research environment is safe, supportive and effective.

[MISSING_PAGE_POST]

. Kibble

## Accessibility

To request copies of this report in large print or in a different format, please contact the Equality, Diversity and Inclusion team at UKRI:

01793 444000

equality@ukri.org

UK Research and Innovation

Polaris House

Swindon

SN2 1FL

The views expressed in this publication are those of the authors and not necessarily those of Advance HE. No part of this publication may be reproduced or transmitted in any form or by any means, electronic or mechanical, including photocopying, recording, or any storage and retrieval system, without the written permission of the copyright owner. Such permission will normally be granted for non-commercial, educational purposes provided that due acknowledgment is given.